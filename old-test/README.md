# Keycloak High Availability con PostgreSQL Streaming Replication

## DescripciÃ³n

Sistema de **Alta Disponibilidad** para Keycloak desplegado en **2 nodos fÃ­sicos separados** con arquitectura **Active-Active**, implementando **PostgreSQL Streaming Replication** nativa y **query routing inteligente** con pgpool-II.

Este proyecto proporciona una soluciÃ³n completa y lista para producciÃ³n diseÃ±ada para:
- **Despliegue en 2 servidores independientes** (NODO 1 + NODO 2)
- **Ambos Keycloak activos simultÃ¡neamente** (cualquier nodo puede recibir trÃ¡fico)
- **Query routing automÃ¡tico**: escrituras â†’ PRIMARY, lecturas â†’ REPLICA
- **Clustering Keycloak** con Infinispan/JGroups para cache distribuido
- **Failover manual** con procedimientos documentados

---

## Tabla de Contenidos

- [DescripciÃ³n](#descripciÃ³n)
- [CaracterÃ­sticas Principales](#caracterÃ­sticas-principales)
- [Arquitectura del Sistema](#arquitectura-del-sistema)
  - [Vista General - 2 Nodos FÃ­sicos](#vista-general---2-nodos-fÃ­sicos)
  - [Diagrama de Componentes por Capa](#diagrama-de-componentes-por-capa)
  - [Flujo de Datos](#flujo-de-datos)
- [Requisitos Previos](#requisitos-previos)
- [Despliegue en 2 Nodos FÃ­sicos](#despliegue-en-2-nodos-fÃ­sicos)
  - [Requisitos de Red Previos](#requisitos-de-red-previos)
  - [Paso 1: Desplegar NODO 1](#paso-1-desplegar-nodo-1-servidor-primario)
  - [Paso 2: Desplegar NODO 2](#paso-2-desplegar-nodo-2-servidor-secundario)
  - [Paso 3: Verificar Clustering](#paso-3-verificar-clustering)
- [VerificaciÃ³n del Sistema (2 Nodos)](#verificaciÃ³n-del-sistema-2-nodos)
- [Acceso a Servicios (2 Nodos)](#acceso-a-servicios-2-nodos)
- [GuÃ­a de Uso - Arquitectura 2 Nodos](#guÃ­a-de-uso---arquitectura-2-nodos)
  - [Comportamiento de Query Routing por Nodo](#comportamiento-de-query-routing-por-nodo)
- [ResoluciÃ³n de Problemas](#resoluciÃ³n-de-problemas)
  - [Problemas EspecÃ­ficos de Arquitectura 2 Nodos](#problemas-especÃ­ficos-de-arquitectura-2-nodos)
  - [Problemas Comunes (Ambos Nodos)](#problemas-comunes-ambos-nodos)
- [Estructura del Proyecto - Arquitectura 2 Nodos](#estructura-del-proyecto---arquitectura-2-nodos)
- [LÃ­mites y Escalabilidad](#lÃ­mites-y-escalabilidad---arquitectura-2-nodos)
- [Costos Estimados](#costos-estimados-cloud-deployment---2-nodos-fÃ­sicos)
- [Referencias y Recursos](#referencias-y-recursos)
- [Historial de Versiones](#historial-de-versiones)

---

## Quick Start - Despliegue RÃ¡pido en 2 Nodos

### Prerrequisitos
- 2 servidores Linux con Docker y Docker Compose instalados
- Red entre servidores (puertos 5432, 7800, 8443 abiertos)
- 4GB RAM mÃ­nimo por servidor

### En NODO 1 (Servidor Primario)
```bash
git clone <repository-url> && cd keycloak_HA
./deploy-nodo1.sh
# âœ… Anota la IP mostrada al finalizar (ej: 192.168.1.100)
```

### En NODO 2 (Servidor Secundario)
```bash
git clone <repository-url> && cd keycloak_HA
./deploy-nodo2.sh
# âŒ¨ï¸  Ingresa la IP del NODO 1 cuando se solicite
```

### Verifica el Cluster
```bash
# En NODO 1
docker logs keycloak-1 | grep "cluster view"
# Expected: (2) [keycloak-1, <NODO2_IP>:7800]

# En NODO 2
docker logs keycloak-2 | grep "cluster view"
# Expected: (2) [keycloak-1, keycloak-2]
```

### Accede a Keycloak
- **NODO 1**: https://<IP_NODO_1>:8443 (admin / admin)
- **NODO 2**: https://<IP_NODO_2>:8443 (admin / admin)

---

## CaracterÃ­sticas Principales

### Arquitectura Distribuida en 2 Nodos

- âœ… **NODO 1 (Servidor FÃ­sico 1)**
  - PostgreSQL PRIMARY (R/W) - Puerto 5432 expuesto
  - Keycloak-1 - HTTPS 8443
  - pgpool-II - Query routing local
  - HAProxy - Balanceo local

- âœ… **NODO 2 (Servidor FÃ­sico 2)**
  - PostgreSQL REPLICA (R/O) - Replica desde NODO 1
  - Keycloak-2 - HTTPS 8443
  - pgpool-II - Proxy a PRIMARY remoto + REPLICA local
  - HAProxy - Proxy remoto + balanceo local

### Base de Datos

- âœ… **PostgreSQL 15 Streaming Replication** nativa
  - ReplicaciÃ³n asÃ­ncrona entre nodos fÃ­sicos
  - Write-Ahead Log (WAL) streaming continuo
  - Sin dependencias externas (Patroni, etcd, Consul)
  - PRIMARY en NODO 1, REPLICA en NODO 2

### Query Routing Inteligente

- âœ… **pgpool-II - Query Routing AutomÃ¡tico** â­ **CRÃTICO para NODO 2**
  - **NODO 1**: Todas las queries al PRIMARY local (<2ms)
  - **NODO 2**: 
    - `SELECT` â†’ REPLICA local (<2ms) âœ… RÃPIDO
    - `INSERT/UPDATE/DELETE` â†’ PRIMARY remoto (10-50ms) âš ï¸ Latencia de red
  - Load balancing automÃ¡tico de lecturas
  - GestiÃ³n transparente de transacciones
  - Connection pooling integrado

- âœ… **HAProxy - Routing por Puerto** (soporte)
  - NODO 1: Puerto 5000 â†’ PRIMARY local
  - NODO 2: Puerto 5000 â†’ PRIMARY remoto (proxy), Puerto 5001 â†’ REPLICA local

### Capa de AplicaciÃ³n

- âœ… **Keycloak 23.0 Cluster** (2 nodos fÃ­sicos)
  - Cache distribuido con Infinispan/JGroups sobre TCP
  - Discovery automÃ¡tico entre nodos vÃ­a TCPPING
  - SincronizaciÃ³n de sesiones entre NODO 1 y NODO 2
  - SSL/TLS habilitado por defecto
  - Ambos nodos activos simultÃ¡neamente (Active-Active)

### Operaciones

- âœ… **Scripts de AutomatizaciÃ³n**
  - Despliegue completo con un solo comando
  - Suite de testing integrada (23 tests automatizados)
  - Procedimientos de failover documentados y scriptados
  - GeneraciÃ³n automÃ¡tica de certificados SSL
  - VerificaciÃ³n continua del estado de replicaciÃ³n

- âœ… **Seguridad**
  - Comunicaciones cifradas SSL/TLS
  - Certificados auto-firmados para desarrollo (reemplazables en producciÃ³n)
  - AutenticaciÃ³n MD5 para conexiones PostgreSQL
  - ConfiguraciÃ³n de `pg_hba.conf` restrictiva

---

## Arquitectura del Sistema

### Vista General - 2 Nodos FÃ­sicos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Usuario / Cliente                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTPS (8443)                   â”‚ HTTPS (8443)
               â–¼                                â–¼
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•— â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘    NODO 1 (Servidor 1)       â•‘ â•‘    NODO 2 (Servidor 2)       â•‘
    â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘ â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
    â•‘  â”‚    Keycloak-1          â”‚  â•‘ â•‘  â”‚    Keycloak-2          â”‚  â•‘
    â•‘  â”‚  (Active - HTTPS 8443) â”‚â—„â”€â•¬â”€â•¬â”€â–ºâ”‚  (Active - HTTPS 8443) â”‚  â•‘
    â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘ â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
    â•‘             â”‚ JGroups TCP    â•‘ â•‘             â”‚ JGroups TCP    â•‘
    â•‘             â”‚ (Puerto 7800)  â•‘ â•‘             â”‚ (Puerto 7800)  â•‘
    â•‘             â–¼                â•‘ â•‘             â–¼                â•‘
    â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘ â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
    â•‘  â”‚   pgpool-II Nodo 1      â”‚ â•‘ â•‘  â”‚   pgpool-II Nodo 2      â”‚ â•‘
    â•‘  â”‚   (Query Routing)       â”‚ â•‘ â•‘  â”‚   (Query Routing Proxy) â”‚ â•‘
    â•‘  â”‚  - Backend: PRIMARY     â”‚ â•‘ â•‘  â”‚  - Backend 0: PRIMARY â”€â”€â•¬â”€â”â•‘
    â•‘  â”‚    (local, weight=1)    â”‚ â•‘ â•‘  â”‚    (remoto, weight=0)   â”‚ â”‚â•‘
    â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘ â•‘  â”‚  - Backend 1: REPLICA   â”‚ â”‚â•‘
    â•‘               â”‚              â•‘ â•‘  â”‚    (local, weight=1)    â”‚ â”‚â•‘
    â•‘               â–¼              â•‘ â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â•‘
    â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘ â•‘               â”‚              â”‚â•‘
    â•‘  â”‚   HAProxy Nodo 1        â”‚ â•‘ â•‘               â–¼              â”‚â•‘
    â•‘  â”‚  - Port 5000: PRIMARY   â”‚ â•‘ â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â•‘
    â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘ â•‘  â”‚   HAProxy Nodo 2        â”‚ â”‚â•‘
    â•‘               â”‚              â•‘ â•‘  â”‚  - Port 5000: nodo1 â—„â”€â”€â”€â•¬â”€â”˜â•‘
    â•‘               â–¼              â•‘ â•‘  â”‚    (PRIMARY remoto)     â”‚  â•‘
    â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘ â•‘  â”‚  - Port 5001: REPLICA   â”‚  â•‘
    â•‘  â”‚  PostgreSQL PRIMARY     â”‚â—„â•¬â”€â•¬â”€â”€â”¤    (local)              â”‚  â•‘
    â•‘  â”‚  (Read / Write)         â”‚â”€â•¬â”€â•¬â”€â–ºâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
    â•‘  â”‚  Puerto 5432 EXPUESTO   â”‚ â•‘ â•‘               â”‚              â•‘
    â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘ â•‘               â–¼              â•‘
    â•‘               â”‚              â•‘ â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
    â•‘               â–¼              â•‘ â•‘  â”‚  PostgreSQL REPLICA     â”‚ â•‘
    â•‘      [pg-primary-data]       â•‘ â•‘  â”‚  (Read Only)            â”‚ â•‘
    â•‘                              â•‘ â•‘  â”‚  PRIMARY_HOST: NODO1_IP â”‚ â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
                                     â•‘               â”‚              â•‘
         ReplicaciÃ³n WAL Stream      â•‘               â–¼              â•‘
         â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•£      [pg-replica-data]       â•‘
                Puerto 5432          â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FLUJO DE DATOS:                                                      â”‚
â”‚                                                                      â”‚
â”‚ NODO 1 (PRIMARY Database):                                          â”‚
â”‚   - Keycloak-1 â†’ pgpool â†’ haproxy:5000 â†’ PRIMARY local (<2ms)      â”‚
â”‚   - Query Routing: Todas las queries al PRIMARY local               â”‚
â”‚                                                                      â”‚
â”‚ NODO 2 (REPLICA Database + Proxy):                                  â”‚
â”‚   - Keycloak-2 READ (SELECT) â†’ pgpool â†’ haproxy:5001 â†’ REPLICA     â”‚
â”‚     local (<2ms) âœ… RÃPIDO                                          â”‚
â”‚   - Keycloak-2 WRITE (INSERT/UPDATE/DELETE) â†’ pgpool â†’             â”‚
â”‚     haproxy:5000 â†’ PRIMARY remoto NODO 1 (10-50ms) âš ï¸ Latencia red â”‚
â”‚                                                                      â”‚
â”‚ KEYCLOAK CLUSTERING:                                                 â”‚
â”‚   - Ambos nodos activos simultÃ¡neamente (Active-Active)             â”‚
â”‚   - SincronizaciÃ³n de cache vÃ­a JGroups TCP (puerto 7800)          â”‚
â”‚   - Discovery: TCPPING con IPs configurables                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Diagrama de Componentes por Capa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE APLICACIÃ“N                               â”‚
â”‚                                                                     â”‚
â”‚  Keycloak-1 (8443) â—„â”€â”€â”€â”€â”€â”€JGroups TCP (7800)â”€â”€â”€â”€â”€â”€â”€â–º Keycloak-2 (8444) â”‚
â”‚         â”‚               Cache distribuido                    â”‚     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜
          â”‚                                                     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CAPA DE ROUTING DE QUERIES                            â”‚
â”‚                                                                     â”‚
â”‚  â­ pgpool-II (9999) - Query Routing AutomÃ¡tico                     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  â”‚ AnÃ¡lisis SQL:                                      â”‚         â”‚
â”‚  â”‚  â”‚  â€¢ INSERT/UPDATE/DELETE/DDL â”€â”€â”€â”€â–º PRIMARY         â”‚         â”‚
â”‚  â”‚  â”‚  â€¢ SELECT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º REPLICA (LB)    â”‚         â”‚
â”‚  â”‚  â”‚  â€¢ Transacciones mixtas â”€â”€â”€â”€â”€â”€â”€â”€â–º PRIMARY         â”‚         â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚  â”‚                                                                 â”‚
â”‚  â””â”€â”€â–º HAProxy (Alternativa - Routing por Puerto)                  â”‚
â”‚       â”œâ”€ Puerto 5000 â”€â”€â”€â”€â”€â”€â”€â”€â–º PRIMARY (garantizado)              â”‚
â”‚       â”œâ”€ Puerto 5001 â”€â”€â”€â”€â”€â”€â”€â”€â–º REPLICA prefer, PRIMARY backup     â”‚
â”‚       â””â”€ Puerto 7000 â”€â”€â”€â”€â”€â”€â”€â”€â–º Stats UI                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                             â”‚
                      â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CAPA DE PERSISTENCIA                               â”‚
â”‚                                                                     â”‚
â”‚  PostgreSQL PRIMARY (5432)          PostgreSQL REPLICA (5433)      â”‚
â”‚  â”œâ”€ Modo: Read/Write               â”œâ”€ Modo: Read-Only             â”‚
â”‚  â”œâ”€ wal_level = replica            â”œâ”€ recovery_mode = standby     â”‚
â”‚  â”œâ”€ max_wal_senders = 10           â”œâ”€ hot_standby = on            â”‚
â”‚  â””â”€ Estado: NOT in recovery        â””â”€ Estado: pg_is_in_recovery   â”‚
â”‚                                                                     â”‚
â”‚  PRIMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€WAL Streamingâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º REPLICA                â”‚
â”‚           (tcp/5432, protocolo binario)                            â”‚
â”‚                                                                     â”‚
â”‚  Latencia tÃ­pica: < 1 segundo (async replication)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos

#### Escenario 1: Usando pgpool-II (Recomendado)

```
1. Cliente se conecta a pgpool-II:9999
2. Cliente envÃ­a: SELECT * FROM users WHERE id = 1;
3. pgpool-II analiza la query:
   - Tipo: SELECT (lectura)
   - DecisiÃ³n: Rutear a REPLICA
   - Backend elegido: backend1 (weight=1, REPLICA vÃ­a HAProxy:5001)
4. pgpool-II forward query a HAProxy:5001
5. HAProxy rutea a postgres-replica:5432
6. REPLICA ejecuta query y retorna resultado
7. pgpool-II retorna resultado al cliente

Casos especiales:
- INSERT INTO users VALUES (...) â†’ pgpool detecta DML â†’ PRIMARY
- BEGIN; SELECT ...; UPDATE ...; COMMIT; â†’ toda la transacciÃ³n al PRIMARY
- SELECT ... FOR UPDATE â†’ detectado como write â†’ PRIMARY
```

#### Escenario 2: Usando HAProxy Directamente

```
Escrituras (puerto 5000):
1. Cliente â†’ HAProxy:5000
2. HAProxy health check: Â¿quiÃ©n es PRIMARY?
   - postgres-primary xinetd check â†’ "200 OK" (es PRIMARY)
   - postgres-replica xinetd check â†’ "503 Service Unavailable" (es REPLICA)
3. HAProxy rutea a postgres-primary:5432
4. Query ejecutada en PRIMARY

Lecturas (puerto 5001):
1. Cliente â†’ HAProxy:5001
2. HAProxy balancea con weight:
   - postgres-replica weight 100 (preferido)
   - postgres-primary weight 50 (backup)
3. ConexiÃ³n establecida (probabilÃ­sticamente a REPLICA)
4. Query ejecutada
```

### Componentes TÃ©cnicos Detallados

#### pgpool-II

**Imagen:** `pgpool/pgpool:latest`  
**Puerto principal:** 9999 (conexiones PostgreSQL)  
**Puerto PCP:** 9898 (administraciÃ³n)  

**ConfiguraciÃ³n clave:**

| ParÃ¡metro | Valor | DescripciÃ³n |
|-----------|-------|-------------|
| `master_slave_mode` | `on` | Habilita modo PRIMARY/REPLICA |
| `load_balance_mode` | `on` | Distribuye SELECTs entre replicas |
| `backend_weight0` | `0` | PRIMARY: peso 0 (solo escrituras) |
| `backend_weight1` | `1` | REPLICA: peso 1 (todas las lecturas) |
| `disable_load_balance_on_write` | `transaction` | Sesiones con writes â†’ PRIMARY |
| `num_init_children` | `32` | Procesos worker pre-forkeados |
| `max_pool` | `4` | Conexiones por proceso hijo |
| `health_check_period` | `10` | VerificaciÃ³n salud cada 10s |

**Backends configurados:**

```
Backend 0 (PRIMARY):
  - Hostname: haproxy
  - Port: 5000
  - Flag: ALWAYS_PRIMARY
  - Weight: 0 (no recibe SELECTs balanceados)
  
Backend 1 (REPLICA):
  - Hostname: haproxy
  - Port: 5001
  - Flag: DISALLOW_TO_FAILOVER
  - Weight: 1 (recibe todos los SELECTs balanceados)
```

#### HAProxy

**Imagen:** `haproxy:2.9-alpine`  
**Puertos expuestos:** 5000 (PRIMARY), 5001 (REPLICA), 7000 (Stats)

**Health Check Logic:**

```haproxy
# DetecciÃ³n de PRIMARY via pg_is_in_recovery
option pgsql-check user postgres

# Backend PRIMARY pool
server postgres-primary postgres-primary:5432 check
  # Si pg_is_in_recovery() = false â†’ UP
  # Si pg_is_in_recovery() = true  â†’ DOWN

# Backend REPLICA pool  
server postgres-replica postgres-replica:5432 check weight 100
server postgres-primary postgres-primary:5432 check weight 50 backup
  # REPLICA preferida, PRIMARY como fallback
```

#### PostgreSQL

**Imagen:** `postgres:15`  
**Protocolo de replicaciÃ³n:** Physical Streaming Replication

**PRIMARY configuration (`postgresql-primary.conf`):**

```ini
wal_level = replica                    # Nivel mÃ­nimo para replicaciÃ³n
max_wal_senders = 10                   # Slots de replicaciÃ³n
wal_keep_size = 1024MB                 # WAL retenido para replicas
hot_standby = on                       # Permite queries en standby
synchronous_commit = off               # Async para mayor rendimiento
```

**REPLICA configuration (`postgresql-replica.conf`):**

```ini
hot_standby = on                       # Acepta queries SELECT
hot_standby_feedback = on              # Previene vacuum conflicts
max_standby_streaming_delay = 30s      # Max delay antes de cancelar query
wal_receiver_status_interval = 2s      # Frecuencia de status reports
```

**AutenticaciÃ³n (`pg_hba.conf`):**

```
# TYPE  DATABASE        USER            ADDRESS                 METHOD
local   all             all                                     trust
host    all             all             127.0.0.1/32            md5
host    all             all             0.0.0.0/0               md5
host    replication     all             0.0.0.0/0               md5
```

#### Keycloak

**Imagen base:** `quay.io/keycloak/keycloak:23.0`  
**OptimizaciÃ³n:** Pre-built para PostgreSQL (`kc.sh build --db=postgres`)

**Cluster configuration:**

```bash
# JGroups discovery via TCP (no multicast)
KC_CACHE_STACK=tcp
JGROUPS_DISCOVERY_PROTOCOL=TCPPING
JGROUPS_DISCOVERY_PROPERTIES=initial_hosts="keycloak-1[7800],keycloak-2[7800]"

# Cache distribuido
KC_CACHE_CONFIG_FILE=cache-ispn-jdbc-ping.xml
```

**ConexiÃ³n a Base de Datos:**

- **OpciÃ³n recomendada:** `KC_DB_URL_HOST=pgpool` `KC_DB_URL_PORT=9999`
- **OpciÃ³n alternativa:** `KC_DB_URL_HOST=haproxy` `KC_DB_URL_PORT=5000`
- **OpciÃ³n directa:** `KC_DB_URL_HOST=postgres-primary` `KC_DB_URL_PORT=5432`

---

## Inicio RÃ¡pido

### Prerequisitos

```bash
# Verificar versiones
docker --version        # Docker 20.10+
docker compose version  # Docker Compose 2.0+

# Requisitos de sistema
# - CPU: 2+ cores recomendado
# - RAM: 4GB mÃ­nimo, 8GB recomendado
# - Disk: 10GB espacio libre
# - OS: Linux (Ubuntu 20.04+, Debian 11+) o macOS
```

### Despliegue en 2 Nodos FÃ­sicos

Este proyecto estÃ¡ diseÃ±ado para desplegarse en **2 servidores fÃ­sicos independientes** con roles especÃ­ficos:

- **NODO 1**: Servidor primario con PostgreSQL PRIMARY y Keycloak-1
- **NODO 2**: Servidor secundario con PostgreSQL REPLICA y Keycloak-2

#### Requisitos de Red Previos

```bash
# OBLIGATORIO: Los 2 nodos deben poder comunicarse entre sÃ­
# Verificar conectividad desde NODO 2 hacia NODO 1:

# (En NODO 2) Test de conectividad PostgreSQL
nc -zv <IP_NODO_1> 5432
# Expected: Connection to <IP_NODO_1> 5432 port [tcp/postgresql] succeeded!

# (En NODO 2) Test de conectividad Keycloak Clustering
nc -zv <IP_NODO_1> 7800
# Expected: Connection to <IP_NODO_1> 7800 port [tcp/*] succeeded!

# ConfiguraciÃ³n Firewall (aplicar en ambos nodos):
# - Puerto 5432/tcp: PostgreSQL (NODO 1 â†’ acepta desde NODO 2)
# - Puerto 7800/tcp: JGroups clustering (bidireccional)
# - Puerto 8443/tcp: HTTPS Keycloak (usuarios externos)

# Ejemplo UFW (Ubuntu/Debian):
# (En NODO 1)
sudo ufw allow from <IP_NODO_2> to any port 5432 proto tcp comment "PostgreSQL replication"
sudo ufw allow from <IP_NODO_2> to any port 7800 proto tcp comment "Keycloak JGroups"
sudo ufw allow 8443/tcp comment "Keycloak HTTPS"

# (En NODO 2)
sudo ufw allow from <IP_NODO_1> to any port 7800 proto tcp comment "Keycloak JGroups"
sudo ufw allow 8443/tcp comment "Keycloak HTTPS"
```

#### Paso 1: Desplegar NODO 1 (Servidor Primario)

```bash
# 1. Clonar repositorio en NODO 1
git clone <repository-url>
cd keycloak_HA

# 2. Ejecutar script de despliegue para NODO 1
./deploy-nodo1.sh

# El script realizarÃ¡:
# [1/7] Crear red Docker (keycloak-ha-nodo1)
# [2/7] Generar certificados SSL auto-firmados
# [3/7] Configurar Keycloak con TCPPING discovery
# [4/7] Construir imÃ¡genes Docker personalizadas
# [5/7] Iniciar servicios (PRIMARY â†’ HAProxy â†’ pgpool â†’ Keycloak-1)
# [6/7] Esperar PostgreSQL PRIMARY (verificaciÃ³n pg_isready)
# [7/7] Verificar Keycloak-1 en https://localhost:8443

# âš ï¸  IMPORTANTE: Al finalizar, el script mostrarÃ¡:
# ============================================================
# âœ… NODO 1 DESPLEGADO EXITOSAMENTE
# IP detectada: 192.168.1.100
#
# âš ï¸  CONFIGURA NODO 2 CON ESTA IP:
# - Edita deploy-nodo2.sh
# - Variable NODO1_IP="192.168.1.100"
# ============================================================

# 3. Anotar la IP mostrada para configurar NODO 2
```

#### Paso 2: Desplegar NODO 2 (Servidor Secundario)

```bash
# 1. Clonar repositorio en NODO 2
git clone <repository-url>
cd keycloak_HA

# 2. Ejecutar script de despliegue para NODO 2
./deploy-nodo2.sh

# El script solicitarÃ¡ interactivamente:
# Ingresa la IP del NODO 1 (PostgreSQL PRIMARY): 192.168.1.100
# Probando conectividad con NODO 1 (192.168.1.100:5432)...
# âœ… ConexiÃ³n exitosa con NODO 1

# El script realizarÃ¡:
# [1/8] Solicitar y validar IP NODO 1
# [2/8] Test conectividad con NODO 1 (puerto 5432)
# [3/8] Actualizar docker-compose-nodo2.yaml con IP NODO 1
# [4/8] Actualizar pgpool-nodo2.conf con IP NODO 1
# [5/8] Actualizar haproxy-nodo2.cfg con resoluciÃ³n remota
# [6/8] Crear red Docker (keycloak-ha-nodo2)
# [7/8] Generar certificados SSL
# [8/8] Iniciar servicios (REPLICA â†’ HAProxy â†’ pgpool â†’ Keycloak-2)
# [9/8] Verificar replicaciÃ³n PostgreSQL (LAG < 10s)
# [10/8] Verificar Keycloak-2 en https://localhost:8443

# Tiempo estimado por nodo: 2-3 minutos
```

#### Paso 3: Verificar Clustering

```bash
# (En NODO 1) Verificar logs de Keycloak-1
docker logs keycloak-1 | grep -i "received new cluster view"
# Expected: 
# Received new cluster view: [keycloak-1|1] (2) [keycloak-1, <NODO2_IP>:7800]

# (En NODO 2) Verificar logs de Keycloak-2
docker logs keycloak-2 | grep -i "received new cluster view"
# Expected:
# Received new cluster view: [keycloak-1|1] (2) [keycloak-1, keycloak-2]

# (En NODO 2) Verificar replicaciÃ³n PostgreSQL
docker exec postgres-replica psql -U postgres -c "SELECT pg_last_wal_receive_lsn(), pg_last_wal_replay_lsn(), (pg_last_wal_receive_lsn() = pg_last_wal_replay_lsn()) AS synced;"
# Expected:
#  pg_last_wal_receive_lsn | pg_last_wal_replay_lsn | synced
# -------------------------+------------------------+--------
#  0/3000148               | 0/3000148              | t

# (En NODO 2) Verificar query routing de pgpool
docker exec pgpool psql -h localhost -p 9999 -U postgres -d keycloak -c "SHOW pool_nodes;"
# Expected:
#  node_id | hostname    | port | status | role    | lb_weight
# ---------+-------------+------+--------+---------+-----------
#  0       | <NODO1_IP>  | 5000 | up     | primary | 0.000000
#  1       | haproxy     | 5001 | up     | standby | 1.000000
```

### VerificaciÃ³n del Sistema (2 Nodos)

```bash
# NOTA: Los tests deben ejecutarse en cada nodo de forma independiente

# (En NODO 1) - Suite de tests locales
./test-nodo1.sh   # En desarrollo - verifica PRIMARY local

# (En NODO 2) - Suite de tests con proxy remoto
./test-nodo2.sh   # En desarrollo - verifica REPLICA + routing remoto

# Tests manuales recomendados:

# ============ Test 1: ReplicaciÃ³n de datos ============
# (En NODO 1) Insertar datos en PRIMARY
docker exec postgres-primary psql -U postgres -d keycloak -c \
  "CREATE TABLE IF NOT EXISTS test_replication (id SERIAL PRIMARY KEY, data TEXT, created_at TIMESTAMP DEFAULT NOW());"

docker exec postgres-primary psql -U postgres -d keycloak -c \
  "INSERT INTO test_replication (data) VALUES ('Test desde NODO 1');"

# (En NODO 2) Verificar datos en REPLICA (esperar 1-2 segundos)
docker exec postgres-replica psql -U postgres -d keycloak -c \
  "SELECT * FROM test_replication;"
# Expected: 1 fila con "Test desde NODO 1"

# ============ Test 2: Query Routing NODO 2 ============
# (En NODO 2) Conectar a pgpool y ejecutar SELECT (debe ir a REPLICA local)
docker exec -e PGPASSWORD=postgres_admin pgpool \
  psql -h localhost -p 9999 -U postgres -d keycloak -c \
  "SELECT 'Lectura desde REPLICA local' AS test;"

# (En NODO 2) Ejecutar INSERT (debe ir a PRIMARY remoto en NODO 1)
docker exec -e PGPASSWORD=postgres_admin pgpool \
  psql -h localhost -p 9999 -U postgres -d keycloak -c \
  "INSERT INTO test_replication (data) VALUES ('Escritura desde NODO 2 vÃ­a proxy');"

# (En NODO 1) Verificar que el INSERT llegÃ³ al PRIMARY
docker exec postgres-primary psql -U postgres -d keycloak -c \
  "SELECT * FROM test_replication WHERE data LIKE '%NODO 2%';"
# Expected: 1 fila con "Escritura desde NODO 2 vÃ­a proxy"

# ============ Test 3: Clustering Keycloak ============
# (En NODO 1) Crear un realm
curl -k https://localhost:8443/admin/realms -H 'Content-Type: application/json' \
  -d '{"realm":"test-realm","enabled":true}'

# (En NODO 2) Verificar que el realm se sincronizÃ³ vÃ­a cachÃ© distribuido
curl -k https://localhost:8443/admin/realms/test-realm
# Expected: 200 OK con JSON del realm
```

### Acceso a Servicios (2 Nodos)

#### NODO 1 (Servidor Primario)

| Servicio | URL/Endpoint | Credenciales | DescripciÃ³n |
|----------|--------------|--------------|-------------|
| **Keycloak-1** | https://<NODO1_IP>:8443 | admin / admin | Keycloak activo primario |
| **pgpool-II** | <NODO1_IP>:9999 | postgres / postgres_admin | Query routing local (todo a PRIMARY) |
| **HAProxy Stats** | http://<NODO1_IP>:7000 | - | Dashboard estadÃ­sticas |
| **PostgreSQL PRIMARY** | <NODO1_IP>:5432 | postgres / postgres_admin | **EXPUESTO** para replicaciÃ³n remota |

**Acceso local desde contenedores NODO 1:**
```bash
# Keycloak-1 local
docker exec keycloak-1 curl -k https://localhost:8443/health

# pgpool local (todo va a PRIMARY)
docker exec -e PGPASSWORD=postgres_admin pgpool \
  psql -h localhost -p 9999 -U postgres -d keycloak -c "SELECT 'OK' AS status;"

# PRIMARY local directo
docker exec postgres-primary psql -U postgres -c "SELECT pg_is_in_recovery();"  # Expected: f (false)
```

#### NODO 2 (Servidor Secundario)

| Servicio | URL/Endpoint | Credenciales | DescripciÃ³n |
|----------|--------------|--------------|-------------|
| **Keycloak-2** | https://<NODO2_IP>:8443 | admin / admin | Keycloak activo secundario |
| **pgpool-II** â­ | <NODO2_IP>:9999 | postgres / postgres_admin | Query routing inteligente:<br>- SELECT â†’ REPLICA local<br>- INSERT/UPDATE/DELETE â†’ PRIMARY remoto |
| **HAProxy Stats** | http://<NODO2_IP>:7000 | - | Dashboard estadÃ­sticas |
| **PostgreSQL REPLICA** | localhost:5432 | postgres / postgres_admin | Solo acceso interno (no expuesto) |

**Acceso local desde contenedores NODO 2:**
```bash
# Keycloak-2 local
docker exec keycloak-2 curl -k https://localhost:8443/health

# pgpool local CON ROUTING AUTOMÃTICO â­
docker exec -e PGPASSWORD=postgres_admin pgpool \
  psql -h localhost -p 9999 -U postgres -d keycloak -c "SELECT 'Lectura local' AS test;"  # â†’ REPLICA local

docker exec -e PGPASSWORD=postgres_admin pgpool \
  psql -h localhost -p 9999 -U postgres -d keycloak -c "INSERT INTO test VALUES ('Write remoto');"  # â†’ PRIMARY remoto

# REPLICA local directo
docker exec postgres-replica psql -U postgres -c "SELECT pg_is_in_recovery();"  # Expected: t (true)
```

---

## GuÃ­a de Uso - Arquitectura 2 Nodos

### Comportamiento de Query Routing por Nodo

#### NODO 1 (PRIMARY Database)

**pgpool-II:** Configurado con 1 backend (PRIMARY local)

```bash
# ConfiguraciÃ³n pgpool-nodo1.conf:
# backend_hostname0 = 'haproxy'
# backend_port0 = 5000
# backend_weight0 = 1
# backend_flag0 = 'ALWAYS_PRIMARY'

# RESULTADO: Todas las queries (SELECT + INSERT/UPDATE/DELETE) â†’ PRIMARY local
```

**Latencia esperada:** <2ms (todo local)

**Uso desde aplicaciones en NODO 1:**
```bash
# Variables de entorno Keycloak-1
KC_DB_URL_HOST=pgpool
KC_DB_URL_PORT=9999
KC_DB_URL_DATABASE=keycloak
KC_DB_USERNAME=postgres
KC_DB_PASSWORD=postgres_admin

# Todas las operaciones son rÃ¡pidas (local):
SELECT * FROM users;           # <2ms â†’ PRIMARY local
INSERT INTO users VALUES (...) # <2ms â†’ PRIMARY local
UPDATE users SET ...;          # <2ms â†’ PRIMARY local
```

#### NODO 2 (REPLICA Database + Proxy a PRIMARY Remoto)

**pgpool-II:** Configurado con 2 backends (PRIMARY remoto + REPLICA local)

```bash
# ConfiguraciÃ³n pgpool-nodo2.conf:
# Backend 0: PRIMARY remoto (NODO 1)
#   backend_hostname0 = '<NODO1_IP>'
#   backend_port0 = 5000
#   backend_weight0 = 0              # âš ï¸  Weight 0 = NO lecturas
#   backend_flag0 = 'ALWAYS_PRIMARY'
#
# Backend 1: REPLICA local
#   backend_hostname1 = 'haproxy'
#   backend_port1 = 5001
#   backend_weight1 = 1              # âœ… Weight 1 = Todas las lecturas
#   backend_flag1 = 'DISALLOW_TO_FAILOVER'

# RESULTADO: 
# - SELECT â†’ Backend 1 (REPLICA local)   âœ… <2ms
# - INSERT/UPDATE/DELETE â†’ Backend 0 (PRIMARY remoto)  âš ï¸ 10-50ms
```

**Latencia esperada:**
- Lecturas (SELECT): <2ms (REPLICA local)
- Escrituras (INSERT/UPDATE/DELETE): 10-50ms (PRIMARY remoto vÃ­a red)

**Uso desde aplicaciones en NODO 2:**
```bash
# Variables de entorno Keycloak-2 (mismas que NODO 1)
KC_DB_URL_HOST=pgpool
KC_DB_URL_PORT=9999
KC_DB_URL_DATABASE=keycloak
KC_DB_USERNAME=postgres
KC_DB_PASSWORD=postgres_admin

# Operaciones con latencia mixta:
SELECT * FROM users;           # âœ… <2ms â†’ REPLICA local (RÃPIDO)
INSERT INTO users VALUES (...) # âš ï¸ 10-50ms â†’ PRIMARY remoto (LATENCIA RED)
UPDATE users SET ...;          # âš ï¸ 10-50ms â†’ PRIMARY remoto (LATENCIA RED)
DELETE FROM users WHERE ...;   # âš ï¸ 10-50ms â†’ PRIMARY remoto (LATENCIA RED)
```

### OpciÃ³n 1: pgpool-II - Query Routing AutomÃ¡tico â­ RECOMENDADO

**Ventajas:**
- âœ… La aplicaciÃ³n NO necesita conocer en quÃ© nodo estÃ¡ desplegada
- âœ… ConfiguraciÃ³n idÃ©ntica de Keycloak en ambos nodos
- âœ… Routing completamente transparente basado en anÃ¡lisis SQL
- âœ… Load balancing automÃ¡tico de queries SELECT (en NODO 2 â†’ REPLICA local)
- âœ… GestiÃ³n inteligente de transacciones (writes â†’ PRIMARY siempre)
- âœ… Connection pooling integrado (reduce overhead de conexiones remotas)
- âœ… Compatible con cualquier driver PostgreSQL estÃ¡ndar

**ConexiÃ³n desde aplicaciÃ³n (idÃ©ntica en ambos nodos):**

```bash
# Variables de entorno ejemplo (FUNCIONA EN AMBOS NODOS)
DB_HOST=pgpool
DB_PORT=9999
DB_NAME=keycloak
DB_USER=postgres
DB_PASSWORD=postgres_admin

# ConfiguraciÃ³n Keycloak (NODO 1 y NODO 2)
KC_DB_URL_HOST=pgpool
KC_DB_URL_PORT=9999
KC_DB_URL_DATABASE=keycloak
KC_DB_USERNAME=postgres
KC_DB_PASSWORD=postgres_admin
```

**Ejemplos de query routing:**

```sql
-- ========== LECTURAS (SELECT) ==========
-- NODO 1: PRIMARY local (<2ms)
-- NODO 2: REPLICA local (<2ms) âœ… RÃPIDO EN AMBOS
SELECT * FROM users WHERE username = 'john';
SELECT COUNT(*) FROM users;
SELECT u.*, p.* FROM users u JOIN profiles p ON u.id = p.user_id;
SELECT * FROM sessions WHERE expiration > NOW();

-- ========== ESCRITURAS (INSERT/UPDATE/DELETE/DDL) ==========
-- NODO 1: PRIMARY local (<2ms)
-- NODO 2: PRIMARY remoto (10-50ms) âš ï¸ LATENCIA RED
INSERT INTO users (id, username, email) VALUES (1, 'john', 'john@example.com');
UPDATE users SET email = 'newemail@example.com' WHERE id = 1;
DELETE FROM users WHERE id = 1;
CREATE TABLE products (id SERIAL PRIMARY KEY, name VARCHAR(255));
ALTER TABLE users ADD COLUMN created_at TIMESTAMP;

-- ========== TRANSACCIONES MIXTAS ==========
-- TODA la transacciÃ³n al PRIMARY (NODO 1 local o NODO 2 remoto)
BEGIN;
  SELECT * FROM users WHERE id = 1;        -- Ejecutado en PRIMARY
  UPDATE users SET login_count = login_count + 1 WHERE id = 1;
COMMIT;

-- ========== QUERIES CON LOCKS (detectadas como writes) ==========
-- Routing: PRIMARY (NODO 1 local o NODO 2 remoto)
SELECT * FROM users WHERE id = 1 FOR UPDATE;
SELECT * FROM products FOR SHARE;
```

-- Queries con locks: detectadas como writes â†’ PRIMARY
SELECT * FROM users WHERE id = 1 FOR UPDATE;
SELECT * FROM products FOR SHARE;
```

**Testing del routing:**

```bash
# Conectar a pgpool-II
docker exec -it -e PGPASSWORD=postgres_admin pgpool \
  psql -h localhost -p 9999 -U postgres -d keycloak

# Ver estado de backends
keycloak=# SHOW pool_nodes;

# Resultado esperado:
#  node_id | hostname | port | status | pg_status | lb_weight | role    | select_cnt
# ---------+----------+------+--------+-----------+-----------+---------+------------
#  0       | haproxy  | 5000 | up     | up        | 0.000000  | primary | 0
#  1       | haproxy  | 5001 | up     | up        | 1.000000  | standby | 1245
#
# lb_weight: 0 = no recibe SELECTs, 1 = recibe todos los SELECTs
# select_cnt: contador de SELECTs ejecutados en cada backend

# Ver estadÃ­sticas de pool
keycloak=# SHOW pool_processes;
```

### OpciÃ³n 2: HAProxy - Routing por Puerto

**Ventajas:**
- âœ… Control explÃ­cito del destino (aplicaciÃ³n decide puerto)
- âœ… Overhead mÃ­nimo (solo TCP proxy, no parsing SQL)
- âœ… Ãštil para debugging y troubleshooting
- âœ… Failover automÃ¡tico despuÃ©s de promociÃ³n

**Limitaciones:**
- âš ï¸ La aplicaciÃ³n debe separar READ de WRITE queries manualmente
- âš ï¸ Puerto 5001 puede rechazar writes si conecta a REPLICA
- âš ï¸ No hay connection pooling

**Uso recomendado:**

```python
# Ejemplo Python con psycopg2
import psycopg2

# Pool de escrituras: SIEMPRE puerto 5000 (PRIMARY garantizado)
write_conn = psycopg2.connect(
    host="haproxy",
    port=5000,
    database="keycloak",
    user="postgres",
    password="postgres_admin"
)

# Pool de lecturas: Puerto 5001 (REPLICA preferida)
read_conn = psycopg2.connect(
    host="haproxy",
    port=5001,
    database="keycloak",
    user="postgres",
    password="postgres_admin"
)

# Escrituras
with write_conn.cursor() as cur:
    cur.execute("INSERT INTO users VALUES (%s, %s)", (1, 'john'))
    write_conn.commit()

# Lecturas
with read_conn.cursor() as cur:
    cur.execute("SELECT * FROM users WHERE id = %s", (1,))
    result = cur.fetchone()
```

**VerificaciÃ³n de routing:**

```bash
# Test escritura puerto 5000 (PRIMARY)
docker exec -e PGPASSWORD=postgres_admin haproxy \
  psql -h localhost -p 5000 -U postgres -d keycloak \
  -c "INSERT INTO test_table VALUES ('test');"
# Resultado: OK

# Test escritura puerto 5001 (puede fallar si conecta a REPLICA)
docker exec -e PGPASSWORD=postgres_admin haproxy \
  psql -h localhost -p 5001 -U postgres -d keycloak \
  -c "INSERT INTO test_table VALUES ('test');"
# Resultado: ERROR: cannot execute INSERT in a read-only transaction (si conecta a REPLICA)

# Ver estadÃ­sticas HAProxy
curl http://localhost:7000
# Dashboard web con estado de backends, conexiones activas, health checks, etc.
```

### OpciÃ³n 3: ConexiÃ³n Directa a PostgreSQL

**Solo para:**
- Debugging y troubleshooting
- Operaciones de administraciÃ³n
- Testing manual

**NO recomendado para aplicaciones en producciÃ³n** (no hay balanceo ni failover)

```bash
# Conectar directamente a PRIMARY
docker exec -it -e PGPASSWORD=postgres_admin postgres-primary \
  psql -h 127.0.0.1 -U postgres -d keycloak

# Conectar directamente a REPLICA (read-only)
docker exec -it -e PGPASSWORD=postgres_admin postgres-replica \
  psql -h 127.0.0.1 -U postgres -d keycloak
```

---

## Suite de Testing Automatizada

El proyecto incluye una **suite completa de 23 tests automatizados** consolidados en un Ãºnico script `test.sh` que verifica todos los aspectos crÃ­ticos del sistema.

### EjecuciÃ³n

```bash
./test.sh
```

### Cobertura de Tests

#### PARTE 1: Tests BÃ¡sicos de ReplicaciÃ³n PostgreSQL (7 tests)

| Test | DescripciÃ³n | VerificaciÃ³n |
|------|-------------|--------------|
| **1.1** | Roles PRIMARY/REPLICA | `pg_is_in_recovery()` en ambos nodos |
| **1.2** | ReplicaciÃ³n de datos | InserciÃ³n en PRIMARY, lectura en REPLICA |
| **1.3** | REPLICA read-only | Intento de escritura debe fallar en REPLICA |
| **1.4** | LAG de replicaciÃ³n | `pg_last_xact_replay_timestamp()` < 10s |
| **1.5** | Keycloak Node 1 | HTTP 200 en https://localhost:8443 |
| **1.6** | Keycloak Node 2 | HTTP 200 en https://localhost:8444 |
| **1.7** | Conectividad cluster | Cache JGroups sincronizado |

**Criterios de Ã©xito:**
- PRIMARY debe retornar `NOT pg_is_in_recovery() = true`
- REPLICA debe retornar `pg_is_in_recovery() = true`
- LAG de replicaciÃ³n debe ser < 30 segundos (Ã³ptimo < 10s)
- Ambos nodos Keycloak deben responder HTTP 200

#### PARTE 2: Tests HAProxy Routing (7 tests)

| Test | DescripciÃ³n | VerificaciÃ³n |
|------|-------------|--------------|
| **2.1** | Puerto 5000 â†’ PRIMARY | Escritura exitosa garantizada |
| **2.2** | Puerto 5001 comportamiento | Escritura puede fallar si conecta a REPLICA |
| **2.3** | MÃºltiples escrituras 5000 | Batch de 5 INSERTs sin errores |
| **2.4** | ReplicaciÃ³n streaming | Datos escritos en PRIMARY aparecen en REPLICA |
| **2.5** | REPLICA rechaza writes | ValidaciÃ³n read-only en standby |
| **2.6** | HAProxy Stats accesible | HTTP 200 en http://localhost:7000 |
| **2.7** | Health checks funcionando | Backends marcados UP/DOWN correctamente |

**Criterios de Ã©xito:**
- Puerto 5000 debe aceptar TODAS las escrituras (100% PRIMARY)
- ReplicaciÃ³n debe completarse en < 5 segundos
- HAProxy Stats debe mostrar estado de backends en tiempo real
- Health checks deben detectar rol PRIMARY/REPLICA correctamente

#### PARTE 3: Tests pgpool-II Routing AutomÃ¡tico (9 tests)

| Test | DescripciÃ³n | VerificaciÃ³n |
|------|-------------|--------------|
| **3.1** | INSERT routing | `INSERT` detectado y ruteado a PRIMARY |
| **3.2** | UPDATE routing | `UPDATE` detectado y ruteado a PRIMARY |
| **3.3** | DELETE routing | `DELETE` detectado y ruteado a PRIMARY |
| **3.4** | SELECT routing | `SELECT` balanceado a REPLICA |
| **3.5** | Batch operations | 10 INSERTs consecutivos sin errores |
| **3.6** | Read verification | SELECTs retornan datos correctos desde REPLICA |
| **3.7** | Transaction handling | TransacciÃ³n mixta (SELECT+UPDATE) al PRIMARY |
| **3.8** | Backend health | 2/2 backends UP y respondiendo |
| **3.9** | Pool statistics | MÃ©tricas de pool_nodes y distribuciÃ³n de queries |

**Criterios de Ã©xito:**
- Todos los DML (INSERT/UPDATE/DELETE) deben ejecutarse en PRIMARY
- SELECTs deben balancearse a REPLICA (backend1, weight=1)
- Transacciones mixtas completas deben ir a PRIMARY
- Ambos backends (PRIMARY y REPLICA) deben estar status "up"
- `select_cnt` de REPLICA debe ser > 0 (recibe queries)

### Ejemplo de Salida

```bash
$ ./test.sh

=========================================================================
  Test Completo: Keycloak HA - PostgreSQL Streaming Replication
=========================================================================

=========================================================================
  PARTE 1: Tests BÃ¡sicos de ReplicaciÃ³n PostgreSQL
=========================================================================

ğŸ“‹ TEST 1.1: Verificar roles PRIMARY/REPLICA
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ… postgres-primary es PRIMARY (NOT in recovery)
  âœ… postgres-replica es REPLICA (in recovery mode)

ğŸ“‹ TEST 1.2: Test de replicaciÃ³n de datos
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ… Tabla creada en PRIMARY
  âœ… 3 filas insertadas en PRIMARY
  â³ Esperando replicaciÃ³n (2 segundos)...
  âœ… REPLICA tiene 3 filas replicadas

ğŸ“‹ TEST 1.3: Verificar que REPLICA es READ-ONLY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ… REPLICA rechaza correctamente escrituras (read-only)

ğŸ“‹ TEST 1.4: Medir LAG de replicaciÃ³n
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â„¹ï¸  LAG actual: 0 segundos
  âœ… LAG < 10s: Excelente

ğŸ“‹ TEST 1.5: Verificar Keycloak acceso
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ… Keycloak-1 (8443) responde: 200 OK
  âœ… Keycloak-2 (8444) responde: 200 OK

=========================================================================
  PARTE 2: Tests de HAProxy Routing
=========================================================================

ğŸ“‹ TEST 2.1: Escritura via HAProxy puerto 5000 (PRIMARY)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ… Puerto 5000 â†’ escritura exitosa en PRIMARY

ğŸ“‹ TEST 2.2: Comportamiento puerto 5001 (REPLICA preferred)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â„¹ï¸  Puerto 5001 puede rechazar escrituras si conecta a REPLICA
  âœ… Comportamiento esperado del puerto 5001

...

=========================================================================
  PARTE 3: Tests de pgpool-II Routing AutomÃ¡tico
=========================================================================

ğŸ“‹ TEST 3.1: INSERT automÃ¡tico a PRIMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ… INSERT ejecutado correctamente via pgpool-II

ğŸ“‹ TEST 3.4: SELECT balanceado a REPLICA
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ… SELECT ejecutado correctamente vÃ­a pgpool-II
  âœ… Dato leÃ­do: test-3.1-xxx

...

=========================================================================
  ğŸ“Š Resumen Final
=========================================================================

Servicios Disponibles:
  â€¢ Keycloak: https://localhost:8443, https://localhost:8444
  â€¢ pgpool-II: localhost:9999 (â­ RECOMENDADO para aplicaciones)
  â€¢ HAProxy: localhost:5000 (PRIMARY), localhost:5001 (REPLICA)
  â€¢ PostgreSQL: localhost:5432 (PRIMARY), localhost:5433 (REPLICA)

ğŸ“Š EstadÃ­sticas:
Total de tests:    23
Tests exitosos:    23
Tests fallidos:    0

ğŸ‰ Â¡TODOS LOS TESTS PASARON!
```

### Tests Individuales por Componente

Aunque se recomienda ejecutar `test.sh` completo, se pueden ejecutar verificaciones especÃ­ficas:

```bash
# Verificar solo estado de replicaciÃ³n
./check-replication.sh

# Salida esperada:
# application_name |  state  | sync_state | write_lag | flush_lag | replay_lag
# ------------------+---------+------------+-----------+-----------+------------
#  walreceiver      | streaming | async    | 00:00:00  | 00:00:00  | 00:00:00

# Verificar estado de pgpool backends
docker exec pgpool psql -h localhost -p 9999 -U postgres \
  -c "SHOW pool_nodes;"

# Verificar estadÃ­sticas HAProxy
curl -s http://localhost:7000 | grep -E "(postgres-primary|postgres-replica)"

# Verificar logs en tiempo real
docker logs -f pgpool --tail 50
docker logs -f haproxy --tail 50
docker logs -f postgres-primary --tail 50
```

---

## Operaciones y Mantenimiento

### Monitoreo del Sistema

#### Estado de ReplicaciÃ³n

```bash
# Script automatizado con mÃ©tricas completas
./check-replication.sh

# Salida esperada:
# ===============================================
#   Estado de ReplicaciÃ³n PRIMARY â†’ REPLICA
# ===============================================
#
# ğŸ“Š InformaciÃ³n de REPLICA conectada:
#   Application Name:  walreceiver
#   Estado:            streaming
#   Sync State:        async
#   Write LAG:         00:00:00.000000
#   Flush LAG:         00:00:00.000000
#   Replay LAG:        00:00:00.000000
#   Prioridad Sync:    0

# VerificaciÃ³n manual desde PRIMARY
docker exec -e PGPASSWORD=postgres_admin postgres-primary \
  psql -h 127.0.0.1 -U postgres -x -c "SELECT * FROM pg_stat_replication;"

# VerificaciÃ³n manual desde REPLICA
docker exec -e PGPASSWORD=postgres_admin postgres-replica \
  psql -h 127.0.0.1 -U postgres -c "
    SELECT 
      pg_is_in_recovery() as is_replica,
      pg_last_wal_receive_lsn() as receive_lsn,
      pg_last_wal_replay_lsn() as replay_lsn,
      EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) as lag_seconds;
  "
```

#### Logs de Servicios

```bash
# PostgreSQL PRIMARY
docker logs postgres-primary -f --tail 100

# Eventos importantes:
# - "database system is ready to accept connections"
# - "replication connection authorized"
# - "streaming replication successfully connected to primary"

# PostgreSQL REPLICA
docker logs postgres-replica -f --tail 100

# Eventos importantes:
# - "entering standby mode"
# - "started streaming WAL from primary"
# - "consistent recovery state reached"

# pgpool-II
docker logs pgpool -f --tail 100

# Eventos importantes:
# - "backend 0 status changed to up"
# - "backend 1 status changed to up"
# - "health check: backend 0 is up"
# - "SELECT routing to backend 1"

# HAProxy
docker logs haproxy -f --tail 100

# Eventos importantes:
# - "Server postgres-primary/postgres-primary is UP"
# - "Server postgres-replica/postgres-replica is UP"
# - "Health check for server postgres-primary succeeded"

# Keycloak
docker logs keycloak-1 -f --tail 100
docker logs keycloak-2 -f --tail 100

# Eventos importantes:
# - "Keycloak 23.0.0 (powered by Quarkus) started"
# - "Infinispan channels connected"
# - "Started clustering services"
```

#### MÃ©tricas de Rendimiento

```bash
# EstadÃ­sticas de pgpool-II
docker exec pgpool psql -h localhost -p 9999 -U postgres -c "
  SHOW pool_processes;
  SHOW pool_pools;
  SHOW pool_nodes;
"

# Ver distribuciÃ³n de queries por backend
docker exec pgpool psql -h localhost -p 9999 -U postgres -c "
  SELECT 
    node_id,
    hostname,
    port,
    status,
    role,
    select_cnt,
    insert_cnt,
    update_cnt,
    delete_cnt
  FROM pool_nodes;
"

# EstadÃ­sticas HAProxy (JSON)
curl -s http://localhost:7000/stats\;csv | column -t -s,

# EstadÃ­sticas PostgreSQL: conexiones activas
docker exec -e PGPASSWORD=postgres_admin postgres-primary \
  psql -h 127.0.0.1 -U postgres -c "
    SELECT 
      datname,
      count(*) as connections,
      count(*) FILTER (WHERE state = 'active') as active,
      count(*) FILTER (WHERE state = 'idle') as idle
    FROM pg_stat_activity
    WHERE datname IS NOT NULL
    GROUP BY datname;
  "

# TamaÃ±o de bases de datos
docker exec -e PGPASSWORD=postgres_admin postgres-primary \
  psql -h 127.0.0.1 -U postgres -c "
    SELECT 
      datname,
      pg_size_pretty(pg_database_size(datname)) as size
    FROM pg_database
    ORDER BY pg_database_size(datname) DESC;
  "
```

### Procedimientos de Failover

#### Failover Manual (PRIMARY â†’ REPLICA)

**Escenario:** El nodo PRIMARY ha fallado y necesita ser reemplazado por REPLICA.

```bash
# Ejecutar script automatizado
./promote-replica.sh

# Pasos ejecutados por el script:
# 1. Verificar estado actual de REPLICA
# 2. Detener PRIMARY (si sigue corriendo)
# 3. Promocionar REPLICA a PRIMARY:
#    - pg_ctl promote
#    - Eliminar recovery.signal
#    - Configurar como standalone PRIMARY
# 4. Verificar nuevo PRIMARY:
#    - pg_is_in_recovery() debe retornar FALSE
#    - Aceptar conexiones R/W
# 5. Actualizar HAProxy (automÃ¡tico vÃ­a health checks)
# 6. Actualizar pgpool-II (automÃ¡tico vÃ­a sr_check)

# DuraciÃ³n estimada: 30-60 segundos
```

**VerificaciÃ³n post-failover:**

```bash
# 1. Verificar que ex-REPLICA es ahora PRIMARY
docker exec -e PGPASSWORD=postgres_admin postgres-replica \
  psql -h 127.0.0.1 -U postgres -t -c "SELECT NOT pg_is_in_recovery();"
# Esperado: t (true)

# 2. Verificar que acepta escrituras
docker exec -e PGPASSWORD=postgres_admin postgres-replica \
  psql -h 127.0.0.1 -U postgres -d keycloak \
  -c "INSERT INTO test_table VALUES ('post-failover-test');"
# Esperado: INSERT 0 1

# 3. Verificar detecciÃ³n en HAProxy
curl -s http://localhost:7000 | grep -A5 "postgres-replica"
# Esperado: postgres-replica marcado como UP en frontend PRIMARY

# 4. Verificar detecciÃ³n en pgpool-II
docker exec pgpool psql -h localhost -p 9999 -U postgres -c "SHOW pool_nodes;"
# Esperado: node 1 (ex-REPLICA) ahora con role="primary"
```

#### ReconstrucciÃ³n de REPLICA despuÃ©s de Failover

Una vez promovida la REPLICA, el antiguo PRIMARY debe ser reconfigurado como nueva REPLICA:

```bash
# 1. Detener contenedor viejo PRIMARY
docker stop postgres-primary
docker rm postgres-primary

# 2. Limpiar datos antiguos
docker volume rm keycloak_ha_postgres_primary_data

# 3. Recrear como REPLICA del nuevo PRIMARY
# Editar docker-compose.yaml: intercambiar configuraciones PRIMARY/REPLICA
# O reconstruir manualmente:

# Iniciar nuevo contenedor REPLICA apuntando al nuevo PRIMARY
docker run -d \
  --name postgres-primary \
  --network keycloak-ha-net \
  -e POSTGRES_PASSWORD=postgres_admin \
  -e PRIMARY_HOST=postgres-replica \  # Ahora apunta al nuevo PRIMARY
  -e PRIMARY_PORT=5432 \
  -v postgres_primary_data:/var/lib/postgresql/data \
  postgres:15

# 4. Configurar replicaciÃ³n (pg_basebackup desde nuevo PRIMARY)
docker exec -it postgres-primary bash
pg_basebackup -h postgres-replica -U postgres -D /var/lib/postgresql/data -Fp -Xs -P -R

# 5. Iniciar PostgreSQL en modo standby
pg_ctl -D /var/lib/postgresql/data start
```

### Backup y RecuperaciÃ³n

#### Backup Completo (pg_basebackup)

```bash
# Backup desde PRIMARY
docker exec postgres-primary bash -c "
  pg_basebackup -U postgres -D /backup/\$(date +%Y%m%d_%H%M%S) -Ft -z -P
"

# Copiar backup fuera del contenedor
docker cp postgres-primary:/backup/20260210_120000.tar.gz ./backups/
```

#### Backup SQL Dump

```bash
# Dump de base de datos especÃ­fica
docker exec -e PGPASSWORD=postgres_admin postgres-primary \
  pg_dump -h 127.0.0.1 -U postgres -d keycloak -F c -f /tmp/keycloak_backup.dump

# Copiar fuera del contenedor
docker cp postgres-primary:/tmp/keycloak_backup.dump ./backups/keycloak_$(date +%Y%m%d).dump

# Dump de todas las bases de datos
docker exec -e PGPASSWORD=postgres_admin postgres-primary \
  pg_dumpall -h 127.0.0.1 -U postgres -f /tmp/full_backup.sql

docker cp postgres-primary:/tmp/full_backup.sql ./backups/
```

#### RestauraciÃ³n

```bash
# Desde SQL dump
docker cp ./backups/keycloak_20260210.dump postgres-primary:/tmp/

docker exec -e PGPASSWORD=postgres_admin postgres-primary \
  pg_restore -h 127.0.0.1 -U postgres -d keycloak -c /tmp/keycloak_20260210.dump

# Verificar integridad post-restauraciÃ³n
./test.sh
```

### Escalado y OptimizaciÃ³n

#### AÃ±adir REPLICA Adicional

```bash
# 1. Crear entrada en docker-compose.yaml
services:
  postgres-replica-2:
    image: postgres:15
    container_name: postgres-replica-2
    environment:
      POSTGRES_PASSWORD: postgres_admin
      PRIMARY_HOST: postgres-primary
      PRIMARY_PORT: 5432
    volumes:
      - postgres_replica_2_data:/var/lib/postgresql/data
      - ./postgres/setup-replica.sh:/docker-entrypoint-initdb.d/setup-replica.sh
    # ... configuraciÃ³n similar a replica-1

# 2. AÃ±adir backend en pgpool.conf
backend_hostname2 = 'postgres-replica-2'
backend_port2 = 5432
backend_weight2 = 1  # DistribuciÃ³n de load balance
backend_flag2 = 'DISALLOW_TO_FAILOVER'

# 3. Actualizar HAProxy haproxy.cfg
backend pg_replica
    server postgres-replica-2 postgres-replica-2:5432 check weight 100

# 4. Desplegar
docker compose up -d postgres-replica-2
```

#### Tuning PostgreSQL

**Para mayor rendimiento en escrituras:**

```ini
# postgresql-primary.conf
shared_buffers = 1GB           # 25% de RAM disponible
effective_cache_size = 3GB     # 75% de RAM disponible
maintenance_work_mem = 256MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1         # Para SSD
effective_io_concurrency = 200
work_mem = 32MB
min_wal_size = 2GB
max_wal_size = 8GB
max_worker_processes = 4
max_parallel_workers_per_gather = 2
max_parallel_workers = 4
```

**Para reducir LAG de replicaciÃ³n:**

```ini
# postgresql-primary.conf
synchronous_commit = remote_apply  # Cambiar de 'off' a 'remote_apply' para sync
synchronous_standby_names = 'walreceiver'  # Replica sincrÃ³nica

# postgresql-replica.conf
hot_standby_feedback = on
wal_receiver_timeout = 30s
max_standby_streaming_delay = 30s
```

#### Tuning pgpool-II

```ini
# pgpool.conf - Para mayor concurrencia
num_init_children = 64        # Aumentar procesos worker
max_pool = 8                  # MÃ¡s conexiones por proceso
child_life_time = 600         # Reciclar procesos cada 10min
connection_cache = on         # Cachear conexiones

# Para mejor performance en reads
load_balance_mode = on
statement_level_load_balance = on
```

---

## ResoluciÃ³n de Problemas

### Problemas EspecÃ­ficos de Arquitectura 2 Nodos

#### NODO 2: No Puede Conectar al PRIMARY Remoto

**SÃ­ntoma (en NODO 2):**
```bash
docker logs postgres-replica | tail -20
# Output:
# FATAL: could not connect to the primary server: connection refused
```

**DiagnÃ³stico:**
```bash
# (En NODO 2) Test conectividad red
ping -c 3 <IP_NODO_1>
nc -zv <IP_NODO_1> 5432
```

**SoluciÃ³n:**
```bash
# (En NODO 1) Abrir firewall para PostgreSQL
sudo ufw allow from <IP_NODO_2> to any port 5432 proto tcp

# (En NODO 2) Verificar PRIMARY_HOST en docker-compose-nodo2.yaml
grep "PRIMARY_HOST" docker-compose-nodo2.yaml

# Re-desplegar si necesario
./cleanup-nodo2.sh && ./deploy-nodo2.sh
```

#### NODO 2: ReplicaciÃ³n con LAG Alto (>10s)

**Causa:** Latencia de red alta o carga excesiva en PRIMARY

**SoluciÃ³n:**
```bash
# (En NODO 2) Medir latencia
ping -c 100 <IP_NODO_1> | tail -2

# Optimizar queries lentas en PRIMARY
# Aumentar resources en docker-compose
```

#### Keycloak Cluster No Se Forma Entre Nodos

**SÃ­ntoma:** Cada nodo ve solo 1 miembro en vez de 2

**SoluciÃ³n:**
```bash
# Abrir puerto 7800 en firewall (ambos nodos)
sudo ufw allow from <IP_OTRO_NODO> to any port 7800 proto tcp

# Verificar IPs en JGROUPS_DISCOVERY_PROPERTIES
# Reiniciar Keycloak en ambos nodos
```

### Problemas Comunes (Ambos Nodos)

### Tests Fallan con Error de AutenticaciÃ³n

**SÃ­ntoma:**
```
psql: error: connection to server failed: authentication failed for user "postgres"
```

**Causa:** Password incorrecta o variable `PGPASSWORD` no configurada.

**SoluciÃ³n:**
```bash
# Verificar que contenedores estÃ¡n corriendo
docker ps | grep -E "(postgres|pgpool|haproxy|keycloak)"

# Verificar logs de autenticaciÃ³n
docker logs postgres-primary | grep -i "authentication"

# Tests automÃ¡ticamente configuran PGPASSWORD, pero para uso manual:
export PGPASSWORD="postgres_admin"

# Verificar pg_hba.conf permite conexiones
docker exec postgres-primary cat /etc/postgresql/pg_hba.conf | grep -v "^#"
```

### Escrituras Fallan en Puerto 5001 (HAProxy)

**SÃ­ntoma:**
```
ERROR: cannot execute INSERT in a read-only transaction
```

**Causa:** HAProxy puerto 5001 puede enrutar a REPLICA (read-only) debido a load balancing.

**SoluciÃ³n:**
```bash
# OpciÃ³n 1: Usar puerto 5000 para escrituras (garantiza PRIMARY)
psql -h localhost -p 5000 -U postgres -d keycloak

# OpciÃ³n 2: Usar pgpool-II (routing automÃ¡tico)
psql -h localhost -p 9999 -U postgres -d keycloak

# OpciÃ³n 3: Conectar directamente a PRIMARY
psql -h localhost -p 5432 -U postgres -d keycloak
```

### pgpool-II No Detecta Backends

**SÃ­ntoma:**
```
SHOW pool_nodes;
node_id | status | pg_status
--------|--------|----------
0       | down   | down
1       | down   | down
```

**DiagnÃ³stico:**
```bash
# 1. Verificar que HAProxy estÃ¡ corriendo
docker ps | grep haproxy

# 2. Verificar logs de pgpool
docker logs pgpool | grep -i "health check"

# 3. Verificar conectividad desde pgpool a HAProxy
docker exec pgpool ping -c 3 haproxy
docker exec pgpool nc -zv haproxy 5000
docker exec pgpool nc -zv haproxy 5001

# 4. Verificar que PostgreSQL responde via HAProxy
docker exec -e PGPASSWORD=postgres_admin pgpool \
  psql -h haproxy -p 5000 -U postgres -c "SELECT 1;"
```

**SoluciÃ³n:**
```bash
# Reiniciar pgpool para forzar health checks
docker restart pgpool

# Esperar 30 segundos para health checks
sleep 30

# Verificar nuevamente
docker exec pgpool psql -h localhost -p 9999 -U postgres -c "SHOW pool_nodes;"
```

### Keycloak No Inicia o No Responde

**SÃ­ntoma:**
```
curl https://localhost:8443
curl: (7) Failed to connect to localhost port 8443: Connection refused
```

**DiagnÃ³stico:**
```bash
# 1. Verificar estado del contenedor
docker ps -a | grep keycloak

# 2. Ver logs completos
docker logs keycloak-1 --tail 200

# Errores comunes:
# - "Caused by: org.postgresql.util.PSQLException: Connection refused"
#   â†’ PostgreSQL no estÃ¡ listo
# - "Caused by: javax.net.ssl.SSLException: Certificate not found"
#   â†’ Certificados SSL no generados
# - "java.lang.OutOfMemoryError: Java heap space"
#   â†’ Aumentar memoria

# 3. Verificar conectividad a DB
docker exec keycloak-1 nc -zv postgres-primary 5432
docker exec keycloak-1 nc -zv pgpool 9999
```

**Soluciones:**

```bash
# Si PostgreSQL no estaba listo: esperar y reiniciar Keycloak
docker restart keycloak-1 keycloak-2

# Si faltan certificados: regenerar
./generate-certs.sh
docker compose restart keycloak-1 keycloak-2

# Si OutOfMemory: aumentar heap en docker-compose.yaml
environment:
  JAVA_OPTS: "-Xms1g -Xmx2g"
```

### Error de ReplicaciÃ³n o LAG Alto

**SÃ­ntoma:**
```
./check-replication.sh
LAG: 45 segundos  # > 30 segundos significa problema
```

**DiagnÃ³stico:**
```bash
# 1. Verificar estado de replicaciÃ³n en PRIMARY
docker exec -e PGPASSWORD=postgres_admin postgres-primary \
  psql -h 127.0.0.1 -U postgres -x -c "
    SELECT 
      application_name,
      state,
      sync_state,
      sent_lsn,
      write_lsn,
      flush_lsn,
      replay_lsn,
      write_lag,
      flush_lag,
      replay_lag
    FROM pg_stat_replication;
  "

# 2. Verificar logs de REPLICA
docker logs postgres-replica | grep -i "replication\|wal\|recovery"

# Errores comunes:
# - "could not receive data from WAL stream: ERROR: requested WAL segment XXX has already been removed"
#   â†’ PRIMARY eliminÃ³ WAL antes que REPLICA pudiera leerlo
# - "terminating walreceiver process due to administrator command"
#   â†’ ReplicaciÃ³n interrumpida manualmente

# 3. Verificar uso de disco en PRIMARY
docker exec postgres-primary df -h /var/lib/postgresql/data

# 4. Verificar CPU y memoria
docker stats --no-stream postgres-primary postgres-replica
```

**Soluciones:**

```bash
# Si WAL fue eliminado: reconstruir REPLICA desde cero
docker stop postgres-replica
docker volume rm keycloak_ha_postgres_replica_data
docker compose up -d postgres-replica

# Si LAG por carga alta: optimizar queries lentas
docker exec -e PGPASSWORD=postgres_admin postgres-primary \
  psql -h 127.0.0.1 -U postgres -x -c "
    SELECT 
      query,
      calls,
      total_exec_time / 1000 as total_seconds,
      mean_exec_time as avg_ms
    FROM pg_stat_statements
    ORDER BY total_exec_time DESC
    LIMIT 10;
  "

# Si LAG por red lenta: verificar latencia
docker exec postgres-replica ping -c 10 postgres-primary
```

### Cluster Keycloak No Sincroniza Cache

**SÃ­ntoma:**
- SesiÃ³n creada en keycloak-1 no existe en keycloak-2
- Cambios de configuraciÃ³n no se propagan

**DiagnÃ³stico:**
```bash
# 1. Verificar logs de clustering
docker logs keycloak-1 | grep -i "jgroups\|infinispan\|cluster"
docker logs keycloak-2 | grep -i "jgroups\|infinispan\|cluster"

# Buscar:
# - âœ… "Received new cluster view: [keycloak-1, keycloak-2]"
# - âŒ "Failed to connect to cluster member"

# 2. Verificar conectividad JGroups (puerto 7800)
docker exec keycloak-1 nc -zv keycloak-2 7800
docker exec keycloak-2 nc -zv keycloak-1 7800

# 3. Verificar red Docker
docker network inspect keycloak-ha-net | grep -A 10 keycloak
```

**Soluciones:**

```bash
# Reiniciar ambos nodos para forzar re-clustering
docker restart keycloak-1 keycloak-2

# Esperar formaciÃ³n de cluster (30-60 segundos)
sleep 60

# Verificar cluster formado
docker logs keycloak-1 | tail -100 | grep "cluster view"
# Esperado: "Received new cluster view: [keycloak-1, keycloak-2]"
```

### HAProxy Stats No Accesible

**SÃ­ntoma:**
```
curl http://localhost:7000
curl: (7) Failed to connect
```

**SoluciÃ³n:**
```bash
# Verificar contenedor HAProxy
docker ps | grep haproxy

# Verificar logs
docker logs haproxy | grep -i "stats\|7000"

# Verificar configuraciÃ³n
docker exec haproxy cat /usr/local/etc/haproxy/haproxy.cfg | grep -A10 "listen stats"

# Reiniciar si es necesario
docker restart haproxy
```

---

## Estructura del Proyecto - Arquitectura 2 Nodos

```
keycloak_HA/
â”‚
â”œâ”€â”€ ğŸ“‹ DocumentaciÃ³n
â”‚   â”œâ”€â”€ README.md                        # â­ DocumentaciÃ³n principal (este archivo)
â”‚   â””â”€â”€ REORGANIZACION.md                # Notas de reorganizaciÃ³n del proyecto
â”‚
â”œâ”€â”€ ğŸ³ Docker Compose - 2 Nodos FÃ­sicos
â”‚   â”œâ”€â”€ docker-compose-nodo1.yaml        # â­ NODO 1: PRIMARY + Keycloak-1
â”‚   â”‚                                    #    - postgres-primary (puerto 5432 EXPUESTO)
â”‚   â”‚                                    #    - haproxy (solo PRIMARY local)
â”‚   â”‚                                    #    - pgpool (1 backend local)
â”‚   â”‚                                    #    - keycloak-1 (puerto 8443)
â”‚   â”‚
â”‚   â”œâ”€â”€ docker-compose-nodo2.yaml        # â­ NODO 2: REPLICA + Keycloak-2 + Proxy
â”‚   â”‚                                    #    - postgres-replica (PRIMARY_HOST configurable)
â”‚   â”‚                                    #    - haproxy (proxy remoto + local)
â”‚   â”‚                                    #    - pgpool (2 backends: remoto+local)
â”‚   â”‚                                    #    - keycloak-2 (puerto 8443)
â”‚   â”‚                                    #    - extra_hosts para resolver NODO 1
â”‚   â”‚
â”‚   â””â”€â”€ docker-compose.yaml              # ğŸ—‚ï¸  LEGACY: Setup monolÃ­tico (no usado)
â”‚
â”œâ”€â”€ ğŸ³ Dockerfiles
â”‚   â”œâ”€â”€ Dockerfile                       # Keycloak optimizado para PostgreSQL
â”‚   â”œâ”€â”€ Dockerfile.patroni               # LEGACY: No usado
â”‚   â”œâ”€â”€ Dockerfile.postgres-primary      # LEGACY: No usado
â”‚   â””â”€â”€ Dockerfile.postgres-replica      # LEGACY: No usado
â”‚
â”œâ”€â”€ ğŸ”§ Scripts de Despliegue (por Nodo)
â”‚   â”œâ”€â”€ deploy-nodo1.sh                  # â­ Despliegue NODO 1 (PRIMARY)
â”‚   â”‚                                    #    1. Detecta IP automÃ¡ticamente
â”‚   â”‚                                    #    2. Configura JGroups con IP
â”‚   â”‚                                    #    3. Despliega PRIMARY + Keycloak-1
â”‚   â”‚                                    #    4. Muestra IP para config NODO 2
â”‚   â”‚
â”‚   â”œâ”€â”€ deploy-nodo2.sh                  # â­ Despliegue NODO 2 (REPLICA + Proxy)
â”‚   â”‚                                    #    1. Solicita IP de NODO 1
â”‚   â”‚                                    #    2. Test conectividad (nc -zv)
â”‚   â”‚                                    #    3. Actualiza configs con sed
â”‚   â”‚                                    #    4. Despliega REPLICA + Keycloak-2
â”‚   â”‚                                    #    5. Verifica LAG replicaciÃ³n
â”‚   â”‚
â”‚   â””â”€â”€ deploy.sh                        # ğŸ—‚ï¸  LEGACY: Setup monolÃ­tico (no usado)
â”‚
â”œâ”€â”€ ğŸ”§ Scripts de Limpieza (por Nodo)
â”‚   â”œâ”€â”€ cleanup-nodo1.sh                 # EliminaciÃ³n completa NODO 1
â”‚   â”œâ”€â”€ cleanup-nodo2.sh                 # EliminaciÃ³n completa NODO 2
â”‚   â””â”€â”€ cleanup.sh                       # ğŸ—‚ï¸  LEGACY: Limpieza monolÃ­tica (no usado)
â”‚
â”œâ”€â”€ ğŸ”§ Scripts de Testing (âš ï¸  EN DESARROLLO)
â”‚   â”œâ”€â”€ test-nodo1.sh                    # TODO: Tests NODO 1 (PRIMARY local)
â”‚   â”œâ”€â”€ test-nodo2.sh                    # TODO: Tests NODO 2 (proxy remoto)
â”‚   â””â”€â”€ test.sh                          # ğŸ—‚ï¸  LEGACY: 23 tests monolÃ­ticos
â”‚
â”œâ”€â”€ ğŸ”§ Scripts de Utilidad
â”‚   â”œâ”€â”€ check-replication.sh             # VerificaciÃ³n estado de replicaciÃ³n
â”‚   â”œâ”€â”€ promote-replica.sh               # Procedimiento de failover manual
â”‚   â””â”€â”€ generate-certs.sh                # GeneraciÃ³n de certificados SSL
â”‚
â”œâ”€â”€ âš™ï¸ ConfiguraciÃ³n PostgreSQL
â”‚   â””â”€â”€ postgres/
â”‚       â”œâ”€â”€ init-primary.sh              # InicializaciÃ³n PRIMARY (usuarios, DB)
â”‚       â”œâ”€â”€ setup-replica.sh             # Setup inicial REPLICA (pg_basebackup)
â”‚       â”œâ”€â”€ pg_hba.conf                  # AutenticaciÃ³n (trust local, md5 remote)
â”‚       â”œâ”€â”€ postgresql-primary.conf      # PRIMARY config (wal_level, max_wal_senders)
â”‚       â””â”€â”€ postgresql-replica.conf      # REPLICA config (hot_standby, recovery)
â”‚
â”œâ”€â”€ ğŸ”€ ConfiguraciÃ³n HAProxy (por Nodo)
â”‚   â””â”€â”€ haproxy/
â”‚       â”œâ”€â”€ haproxy-nodo1.cfg            # NODO 1: Solo PRIMARY local (5000)
â”‚       â”‚                                # - Frontend 5000 â†’ postgres-primary
â”‚       â”‚                                # - Stats 7000
â”‚       â”‚
â”‚       â”œâ”€â”€ haproxy-nodo2.cfg            # NODO 2: Proxy remoto + REPLICA local
â”‚       â”‚                                # - Frontend 5000 â†’ nodo1-primary (remoto)
â”‚       â”‚                                # - Frontend 5001 â†’ postgres-replica (local)
â”‚       â”‚                                # - Stats 7000
â”‚       â”‚
â”‚       â””â”€â”€ haproxy.cfg                  # ğŸ—‚ï¸  LEGACY: Config monolÃ­tica (no usado)
â”‚
â”œâ”€â”€ ğŸ”„ ConfiguraciÃ³n pgpool-II (por Nodo)
â”‚   â””â”€â”€ pgpool/
â”‚       â”œâ”€â”€ pgpool-nodo1.conf            # â­ NODO 1: 1 backend (PRIMARY local)
â”‚       â”‚                                # - backend_hostname0 = 'haproxy'
â”‚       â”‚                                # - backend_weight0 = 1
â”‚       â”‚                                # - backend_flag0 = 'ALWAYS_PRIMARY'
â”‚       â”‚
â”‚       â”œâ”€â”€ pgpool-nodo2.conf            # â­ NODO 2: 2 backends (remoto+local)
â”‚       â”‚                                # - Backend 0: PRIMARY remoto (weight=0)
â”‚       â”‚                                #   * backend_hostname0 = '<NODO1_IP>'
â”‚       â”‚                                #   * backend_flag0 = 'ALWAYS_PRIMARY'
â”‚       â”‚                                # - Backend 1: REPLICA local (weight=1)
â”‚       â”‚                                #   * backend_hostname1 = 'haproxy'
â”‚       â”‚                                #   * backend_weight1 = 1 (lecturas aquÃ­)
â”‚       â”‚                                # - health_check_timeout = 30 (red remota)
â”‚       â”‚                                # - connection_cache = on
â”‚       â”‚
â”‚       â”œâ”€â”€ pgpool.conf                  # ğŸ—‚ï¸  LEGACY: Config monolÃ­tica (no usado)
â”‚       â”œâ”€â”€ pool_hba.conf                # AutenticaciÃ³n pgpool (trust/md5)
â”‚       â””â”€â”€ pool_passwd                  # Passwords MD5 (postgres, keycloak)
â”‚
â”œâ”€â”€ ğŸ” Certificados SSL
â”‚   â””â”€â”€ certs/
â”‚       â”œâ”€â”€ keycloak.crt                 # Certificado pÃºblico (auto-firmado)
â”‚       â”œâ”€â”€ keycloak.key                 # Clave privada
â”‚       â””â”€â”€ keycloak.p12                 # Keystore PKCS12 (para Keycloak)
â”‚
â””â”€â”€ ğŸ—‚ï¸ old/                               # Directorio de archivos legacy (Patroni, etc.)
    â””â”€â”€ ...                              # No usado en arquitectura actual
```

### Flujo de Despliegue Recomendado

```
1. (En NODO 1) git clone && cd keycloak_HA
2. (En NODO 1) ./deploy-nodo1.sh
3. (En NODO 1) Anotar IP mostrada (ej: 192.168.1.100)
4. (En NODO 2) git clone && cd keycloak_HA
5. (En NODO 2) ./deploy-nodo2.sh  # IngresarÃ¡ IP de NODO 1
6. (En ambos)  Verificar clustering con docker logs
```

### Archivos Clave para Modificar (ConfiguraciÃ³n Avanzada)

| Archivo | PropÃ³sito | CuÃ¡ndo Modificar |
|---------|-----------|------------------|
| `docker-compose-nodo1.yaml` | Servicios NODO 1 | Cambiar puertos, resources, env vars |
| `docker-compose-nodo2.yaml` | Servicios NODO 2 | Cambiar PRIMARY_HOST, resources |
| `pgpool/pgpool-nodo1.conf` | Query routing NODO 1 | Ajustar connection pooling |
| `pgpool/pgpool-nodo2.conf` | Query routing NODO 2 | Ajustar timeouts para red, weights |
| `haproxy/haproxy-nodo2.cfg` | Proxy remoto NODO 2 | Cambiar IPs backend PRIMARY remoto |
| `postgres/postgresql-primary.conf` | Primary tuning | Performance tuning, WAL settings |
| `deploy-nodo1.sh` | AutomatizaciÃ³n NODO 1 | Personalizar pasos de despliegue |
| `deploy-nodo2.sh` | AutomatizaciÃ³n NODO 2 | Cambiar validaciones, IPs default |

---

## Estructura del Proyecto LEGACY (MonolÃ­tico)

```
keycloak_HA/
â”‚
â”œâ”€â”€ ğŸ“‹ DocumentaciÃ³n
â”‚   â”œâ”€â”€ README.md                    # DocumentaciÃ³n principal (este archivo)
â”‚   â””â”€â”€ REORGANIZACION.md            # Notas de reorganizaciÃ³n del proyecto
â”‚
â”œâ”€â”€ ğŸ³ Docker & OrquestaciÃ³n
â”‚   â”œâ”€â”€ docker-compose.yaml          # DefiniciÃ³n de servicios (6 servicios)
â”‚   â”œâ”€â”€ Dockerfile                   # Keycloak optimizado para PostgreSQL
â”‚   â”œâ”€â”€ Dockerfile.patroni           # (No usado - legacy)
â”‚   â”œâ”€â”€ Dockerfile.postgres-primary  # (No usado - legacy)
â”‚   â””â”€â”€ Dockerfile.postgres-replica  # (No usado - legacy)
â”‚
â”œâ”€â”€ ğŸ”§ Scripts de OperaciÃ³n
â”‚   â”œâ”€â”€ deploy.sh                    # â­ Despliegue completo automatizado
â”‚   â”œâ”€â”€ test.sh                      # â­ Suite de 23 tests consolidados
â”‚   â”œâ”€â”€ cleanup.sh                   # EliminaciÃ³n completa del entorno
â”‚   â”œâ”€â”€ check-replication.sh         # VerificaciÃ³n estado de replicaciÃ³n
â”‚   â”œâ”€â”€ promote-replica.sh           # Procedimiento de failover manual
â”‚   â””â”€â”€ generate-certs.sh            # GeneraciÃ³n de certificados SSL
â”‚
â”œâ”€â”€ âš™ï¸ ConfiguraciÃ³n PostgreSQL
â”‚   â””â”€â”€ postgres/
â”‚       â”œâ”€â”€ init-primary.sh          # InicializaciÃ³n PRIMARY (usuarios, DB)
â”‚       â”œâ”€â”€ setup-replica.sh         # Setup inicial REPLICA (pg_basebackup)
â”‚       â”œâ”€â”€ replica-entrypoint.sh    # Entrypoint customizado REPLICA
â”‚       â”œâ”€â”€ pg_hba.conf              # AutenticaciÃ³n (trust local, md5 remote)
â”‚       â”œâ”€â”€ postgresql-primary.conf  # ConfiguraciÃ³n PRIMARY (wal_level, max_wal_senders)
â”‚       â””â”€â”€ postgresql-replica.conf  # ConfiguraciÃ³n REPLICA (hot_standby, recovery)
â”‚
â”œâ”€â”€ ğŸ”€ ConfiguraciÃ³n HAProxy
â”‚   â””â”€â”€ haproxy/
â”‚       â””â”€â”€ haproxy.cfg              # Routing por puerto + health checks
â”‚                                    # - Frontend primary: puerto 5000
â”‚                                    # - Frontend replica: puerto 5001
â”‚                                    # - Stats: puerto 7000
â”‚
â”œâ”€â”€ ğŸ”„ ConfiguraciÃ³n pgpool-II
â”‚   â””â”€â”€ pgpool/
â”‚       â”œâ”€â”€ pgpool.conf              # â­ ConfiguraciÃ³n principal query routing
â”‚       â”‚                            # - master_slave_mode=on
â”‚       â”‚                            # - load_balance_mode=on
â”‚       â”‚                            # - backend definitions (PRIMARY/REPLICA)
â”‚       â”œâ”€â”€ pool_hba.conf            # AutenticaciÃ³n pgpool (trust/md5)
â”‚       â””â”€â”€ pool_passwd              # Passwords MD5 (postgres, keycloak)
â”‚
â”œâ”€â”€ ğŸ” Certificados SSL
â”‚   â””â”€â”€ certs/
â”‚       â”œâ”€â”€ keycloak.crt             # Certificado pÃºblico (generado)
â”‚       â”œâ”€â”€ keycloak.key             # Clave privada (generado)
â”‚       â””â”€â”€ keycloak.p12             # Keystore PKCS12 para Keycloak (generado)
â”‚
â””â”€â”€ ğŸ“¦ Old Files (Referencia)
    â””â”€â”€ old/
        â”œâ”€â”€ Dockerfiles antiguos
        â”œâ”€â”€ Scripts de Patroni (no usado)
        â””â”€â”€ DocumentaciÃ³n legacy
```

### DescripciÃ³n de Componentes Clave

#### docker-compose.yaml

Define 6 servicios interconectados:

1. **postgres-primary**: PostgreSQL 15 en modo PRIMARY (R/W)
   - Volumen persistente: `postgres_primary_data`
   - Scripts de inicializaciÃ³n: `init-primary.sh`
   - Health check: `pg_isready`

2. **postgres-replica**: PostgreSQL 15 en modo REPLICA (R/O)
   - Volumen persistente: `postgres_replica_data`
   - Scripts de setup: `setup-replica.sh`, `replica-entrypoint.sh`
   - Dependencia: espera PRIMARY healthy

3. **haproxy**: HAProxy 2.9-alpine
   - Puertos: 5000 (PRIMARY), 5001 (REPLICA), 7000 (Stats)
   - Health checks via `option pgsql-check`
   - Dependencia: espera PRIMARY y REPLICA healthy

4. **pgpool**: pgpool/pgpool:latest
   - Puerto: 9999 (PostgreSQL), 9898 (PCP admin)
   - 29 variables de entorno para configuraciÃ³n dinÃ¡mica
   - VolÃºmenes: `pgpool.conf`, `pool_hba.conf`, `pool_passwd`
   - Dependencia: espera HAProxy healthy

5. **keycloak-1**: Keycloak 23.0 (nodo primario)
   - Puerto HTTPS: 8443
   - Puerto JGroups: 7800
   - ConexiÃ³n DB via pgpool:9999

6. **keycloak-2**: Keycloak 23.0 (nodo secundario)
   - Puerto HTTPS: 8444
   - Puerto JGroups: 7801
   - Clustering con keycloak-1

#### test.sh - Suite de Testing Consolidada

Script completo de 23 tests organizados en 3 partes:

**Estructura interna:**
```bash
# Variables globales
TOTAL_TESTS=0
PASSED_TESTS=0
FAILED_TESTS=0

# Funciones helper
pass_test() { ... }  # Incrementa contador de Ã©xitos
fail_test() { ... }  # Incrementa contador de fallos

# PARTE 1: Tests BÃ¡sicos (TEST 1.1 - 1.7)
# - VerificaciÃ³n de roles PRIMARY/REPLICA
# - ReplicaciÃ³n de datos
# - ProtecciÃ³n read-only en REPLICA
# - MediciÃ³n de LAG
# - Conectividad Keycloak

# PARTE 2: Tests HAProxy (TEST 2.1 - 2.7)
# - Routing por puerto (5000/5001)
# - Behavior de escrituras/lecturas por puerto
# - VerificaciÃ³n replicaciÃ³n streaming
# - Acceso a Stats

# PARTE 3: Tests pgpool-II (TEST 3.1 - 3.9)
# - Routing automÃ¡tico DML (INSERT/UPDATE/DELETE)
# - Load balancing de SELECTs
# - Transacciones complejas
# - Estado de backends y health checks

# Resumen final
echo "Total tests: $TOTAL_TESTS"
echo "Passed: $PASSED_TESTS"
echo "Failed: $FAILED_TESTS"
```

#### pgpool.conf - ConfiguraciÃ³n de Query Routing

ConfiguraciÃ³n optimizada para:
- **Routing inteligente**: AnÃ¡lisis sintÃ¡ctico de queries SQL
- **Load balancing**: DistribuciÃ³n de SELECTs entre replicas
- **Connection pooling**: 32 procesos Ã— 4 conexiones = 128 conexiones mÃ¡ximas
- **Health checks**: VerificaciÃ³n cada 10 segundos
- **Streaming replication check**: DetecciÃ³n automÃ¡tica de roles

**ParÃ¡metros crÃ­ticos:**
```ini
master_slave_mode = on               # Habilita modo PRIMARY/REPLICA
load_balance_mode = on               # Distribuye SELECTs
disable_load_balance_on_write = transaction  # Sesiones con writes â†’ PRIMARY

backend_weight0 = 0                  # PRIMARY: no recibe SELECTs balanceados
backend_weight1 = 1                  # REPLICA: recibe todos los SELECTs

health_check_period = 10             # Check salud cada 10s
sr_check_period = 10                 # Check streaming replication cada 10s
```

---

## Consideraciones de ProducciÃ³n

### Checklist Pre-ProducciÃ³n

#### Seguridad

- [ ] **Certificados SSL vÃ¡lidos**: Reemplazar certificados auto-firmados por CA vÃ¡lida
  ```bash
  # Generar CSR para CA
  openssl req -new -key certs/keycloak.key -out certs/keycloak.csr
  # Enviar CSR a CA y obtener certificado firmado
  # Reemplazar certs/keycloak.crt con certificado firmado
  ```

- [ ] **Cambiar passwords por defecto**:
  - PostgreSQL: `postgres_admin` â†’ password fuerte
  - Keycloak admin: `admin/admin` â†’ credenciales seguras
  - Actualizar en todos los archivos:
    - `docker-compose.yaml` (variables de entorno)
    - `postgres/pg_hba.conf`
    - `pgpool/pool_passwd` (regenerar MD5)
    - Scripts de testing

- [ ] **Configurar firewall**:
  ```bash
  # Ejemplo con ufw (Ubuntu)
  ufw allow 8443/tcp   # Keycloak HTTPS
  ufw allow 8444/tcp   # Keycloak HTTPS node 2
  ufw deny 5432/tcp    # PostgreSQL PRIMARY (solo interno)
  ufw deny 5433/tcp    # PostgreSQL REPLICA (solo interno)
  ufw deny 9999/tcp    # pgpool (solo interno Docker)
  ufw deny 7000/tcp    # HAProxy stats (solo interno)
  ```

- [ ] **Habilitar SSL en PostgreSQL**:
  ```ini
  # postgresql-primary.conf y postgresql-replica.conf
  ssl = on
  ssl_cert_file = '/etc/ssl/certs/server.crt'
  ssl_key_file = '/etc/ssl/private/server.key'
  ssl_ca_file = '/etc/ssl/certs/ca.crt'
  
  # pg_hba.conf: cambiar 'host' por 'hostssl'
  hostssl all all 0.0.0.0/0 md5
  ```

#### Alta Disponibilidad

- [ ] **Configurar backups automÃ¡ticos**:
  ```bash
  # Cron job ejemplo: backup diario a las 2 AM
  0 2 * * * /home/user/keycloak_HA/scripts/backup.sh >> /var/log/pg_backup.log 2>&1
  ```

- [ ] **Implementar monitoreo**:
  - Prometheus + Grafana para mÃ©tricas
  - Alertas sobre:
    - LAG de replicaciÃ³n > 30 segundos
    - Backends down en pgpool/HAProxy
    - Uso de disco > 80%
    - Conexiones PostgreSQL > 80% del lÃ­mite

- [ ] **Documentar procedimientos de recuperaciÃ³n**:
  - Runbook de failover PRIMARY â†’ REPLICA
  - Procedimiento de reconstrucciÃ³n de REPLICA
  - Procedimiento de restauraciÃ³n desde backup
  - Contactos de emergencia y escalaciÃ³n

- [ ] **Configurar replicaciÃ³n sincrÃ³nica (opcional)**:
  ```ini
  # postgresql-primary.conf
  synchronous_commit = on
  synchronous_standby_names = 'walreceiver'
  ```
  âš ï¸ **Impacto**: Menor rendimiento de escritura, pero sin pÃ©rdida de datos en failover

- [ ] **AÃ±adir REPLICA adicional** (para mayor redundancia)

#### Rendimiento

- [ ] **Tuning PostgreSQL** segÃºn hardware disponible
  - Ver secciÃ³n "Escalado y OptimizaciÃ³n" mÃ¡s arriba
  - Usar [PGTune](https://pgtune.leopard.in.ua/) para recomendaciones

- [ ] **Ajustar pgpool connection pooling**:
  ```ini
  # Para workloads con muchos clientes concurrentes
  num_init_children = 100
  max_pool = 4
  ```

- [ ] **Configurar pgBouncer adicional** (opcional):
  - Para connection pooling mÃ¡s agresivo
  - Recomendado si Keycloak tiene >500 conexiones concurrentes

- [ ] **Habilitar query caching** en pgpool (para reads intensivos):
  ```ini
  memory_cache_enabled = on
  memqcache_method = 'memcached'
  ```

#### Operaciones

- [ ] **Configurar logs centralizados**:
  - Syslog, ELK Stack, o Loki + Grafana
  - RetenciÃ³n: mÃ­nimo 30 dÃ­as

- [ ] **Configurar lÃ­mites de recursos en Docker**:
  ```yaml
  # docker-compose.yaml
  services:
    postgres-primary:
      deploy:
        resources:
          limits:
            cpus: '2'
            memory: 4G
          reservations:
            cpus: '1'
            memory: 2G
  ```

- [ ] **Implementar health checks externos**:
  - Pingdom, UptimeRobot, o similar
  - Verificar endpoints:
    - https://keycloak.domain.com/health
    - https://keycloak.domain.com/metrics

- [ ] **Planificar ventanas de mantenimiento**:
  - Actualizaciones de PostgreSQL: trimestral
  - Actualizaciones de Keycloak: mensual
  - Pruebas de failover: mensual

### LÃ­mites y Escalabilidad - Arquitectura 2 Nodos

**ConfiguraciÃ³n actual soporta:**
- **Conexiones concurrentes por nodo**: ~250 (vÃ­a pgpool pooling)
- **Conexiones concurrentes totales**: ~500 (ambos nodos)
- **Throughput de escritura**: 
  - NODO 1: ~5,000 TPS (transactions per second) - LOCAL
  - NODO 2: ~1,500 TPS - Limitado por latencia de red al PRIMARY remoto (10-50ms)
- **Throughput de lectura**: 
  - NODO 1: ~7,500 QPS (queries per second) - PRIMARY local
  - NODO 2: ~7,500 QPS - REPLICA local (sin latencia de red)
  - **Total reads**: ~15,000 QPS combinados
- **Usuarios Keycloak**: ~50,000 activos simultÃ¡neos (distribuidos entre 2 nodos)

**CaracterÃ­sticas de Performance por Nodo:**

| MÃ©trica | NODO 1 (PRIMARY) | NODO 2 (REPLICA + Proxy) |
|---------|------------------|--------------------------|
| **Latencia SELECT** | <2ms (local) | <2ms (REPLICA local) âœ… |
| **Latencia INSERT/UPDATE/DELETE** | <2ms (local) âœ… | 10-50ms (PRIMARY remoto) âš ï¸ |
| **Throughput Escritura** | ~5,000 TPS | ~1,500 TPS |
| **Throughput Lectura** | ~7,500 QPS | ~7,500 QPS |
| **Casos de Uso Ideales** | Admin panel, masive writes | Public-facing, read-heavy |

**Recomendaciones de DistribuciÃ³n de Carga:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ESTRATEGIA RECOMENDADA: Routing por tipo de aplicaciÃ³n      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚ NODO 1 (PRIMARY - Latencia baja en escrituras):            â”‚
â”‚   âœ… Admin panels (Keycloak Admin Console)                  â”‚
â”‚   âœ… Batch processing / ETL                                 â”‚
â”‚   âœ… Background jobs con writes frecuentes                  â”‚
â”‚   âœ… APIs internas de gestiÃ³n                               â”‚
â”‚                                                              â”‚
â”‚ NODO 2 (REPLICA - Latencia baja en lecturas):              â”‚
â”‚   âœ… Aplicaciones pÃºblicas read-heavy                       â”‚
â”‚   âœ… APIs de autenticaciÃ³n/autorizaciÃ³n (OAuth2, OIDC)     â”‚
â”‚   âœ… Servicios de consulta (user info, token validation)   â”‚
â”‚   âš ï¸  Admin operations (con latencia aceptable 10-50ms)    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Para escalar mÃ¡s allÃ¡ (siguientes pasos):**

1. **Escalar lecturas**: Agregar mÃ¡s nodos REPLICA
   ```
   NODO 3, NODO 4, ... NODO N: PostgreSQL REPLICA adicionales
   - Cada REPLICA puede servir ~7,500 QPS adicionales
   - ReplicaciÃ³n desde PRIMARY (NODO 1) vÃ­a WAL streaming
   - Load balancer externo (HAProxy/pgpool) distribuye SELECTs
   ```

2. **Escalar escrituras**: Sharding o partitioning
   ```
   - PostgreSQL 15 Declarative Partitioning (por rango/hash)
   - PostgreSQL 16+ Logical Replication (multi-regiÃ³n)
   - Citus extension (sharding horizontal)
   - NOTA: Requiere cambios en aplicaciÃ³n
   ```

3. **Escalar Keycloak**: Cluster mÃ¡s grande
   ```
   - 4-6 nodos Keycloak (Kubernetes + HPA)
   - External cache (Redis/Valkey) para sesiones
   - Separar Admin Realm de User Realms
   ```

4. **Optimizar latencia NODO 2 â†’ PRIMARY**:
   ```
   - Upgrade red interna: 10Gbps+ entre nodos
   - Reducir latencia fÃ­sica: <1ms RTT ideal
   - Considerar connection pooler adicional: PgBouncer
   ```

### Costos Estimados (Cloud Deployment - 2 Nodos FÃ­sicos)

**AWS ejemplo (us-east-1):**
- **NODO 1**: 1x EC2 c6g.2xlarge (PRIMARY + Keycloak-1): $210/mes
- **NODO 2**: 1x EC2 c6g.2xlarge (REPLICA + Keycloak-2): $210/mes
- 2x EBS gp3 500GB (PRIMARY + REPLICA data): $80/mes
- Application Load Balancer (para Keycloak): $25/mes
- Network Transfer entre nodos (estimado 100GB/mes): $9/mes
- **Total estimado**: ~$534/mes

**GCP ejemplo (us-central1):**
- **NODO 1**: 1x n2-standard-8 (PRIMARY + Keycloak-1): $195/mes
- **NODO 2**: 1x n2-standard-8 (REPLICA + Keycloak-2): $195/mes
- 2x Persistent Disk SSD 500GB: $170/mes
- Cloud Load Balancing: $18/mes
- Network egress (interno regional): ~$5/mes
- **Total estimado**: ~$583/mes

**Azure ejemplo (East US):**
- **NODO 1**: 1x Standard_D8s_v5 (PRIMARY + Keycloak-1): $280/mes
- **NODO 2**: 1x Standard_D8s_v5 (REPLICA + Keycloak-2): $280/mes
- 2x Premium SSD 512GB: $150/mes
- Azure Load Balancer (Basic): $18/mes
- Network entre VMs misma regiÃ³n: ~$0
- **Total estimado**: ~$728/mes

**Colocation / Bare Metal (2 servidores fÃ­sicos):**
- 2x Servidores Dell PowerEdge R450 (Intel Xeon, 64GB RAM, 2TB SSD): $8,000 CAPEX
- Colocation (2U, 10Gbps, energÃ­a): $300/mes
- AmortizaciÃ³n hardware (3 aÃ±os): $222/mes
- **Total mes**: ~$522/mes (sin incluir CAPEX inicial)

---

## Referencias y Recursos

### DocumentaciÃ³n Oficial

- **PostgreSQL**:
  - [Streaming Replication](https://www.postgresql.org/docs/15/warm-standby.html)
  - [High Availability](https://www.postgresql.org/docs/15/high-availability.html)
  - [WAL Configuration](https://www.postgresql.org/docs/15/wal-configuration.html)
  - [pg_basebackup](https://www.postgresql.org/docs/15/app-pgbasebackup.html)

- **pgpool-II**:
  - [Official Documentation](https://www.pgpool.net/docs/latest/en/html/)
  - [Query Routing](https://www.pgpool.net/docs/latest/en/html/runtime-config-load-balancing.html)
  - [Streaming Replication](https://www.pgpool.net/docs/latest/en/html/runtime-streaming-replication-check.html)
  - [Connection Pooling](https://www.pgpool.net/docs/latest/en/html/runtime-config-connection-pooling.html)

- **HAProxy**:
  - [Configuration Manual](http://cbonte.github.io/haproxy-dconv/2.9/configuration.html)
  - [PostgreSQL Health Checks](http://cbonte.github.io/haproxy-dconv/2.9/configuration.html#option%20pgsql-check)
  - [Load Balancing Algorithms](http://cbonte.github.io/haproxy-dconv/2.9/configuration.html#4.2-balance)

- **Keycloak**:
  - [Server Configuration](https://www.keycloak.org/server/configuration)
  - [Caching and Clustering](https://www.keycloak.org/server/caching)
  - [Database Configuration](https://www.keycloak.org/server/db)

- **Docker**:
  - [Compose File Reference](https://docs.docker.com/compose/compose-file/)
  - [Networking](https://docs.docker.com/network/)
  - [Health Checks](https://docs.docker.com/engine/reference/builder/#healthcheck)

### Herramientas Recomendadas

- **Monitoreo**:
  - [pgwatch2](https://github.com/cybertec-postgresql/pgwatch2) - PostgreSQL monitoring
  - [pg_stat_monitor](https://github.com/percona/pg_stat_monitor) - Query performance
  - [Grafana Dashboard para PostgreSQL](https://grafana.com/grafana/dashboards/9628)

- **Backup**:
  - [pgBackRest](https://pgbackrest.org/) - Enterprise-grade backup solution
  - [Barman](https://www.pgbarman.org/) - Backup and Recovery Manager
  - [WAL-G](https://github.com/wal-g/wal-g) - Archival tool

- **Testing**:
  - [pgbench](https://www.postgresql.org/docs/current/pgbench.html) - PostgreSQL benchmarking
  - [k6](https://k6.io/) - Load testing Keycloak endpoints
  - [Apache JMeter](https://jmeter.apache.org/) - Performance testing

- **Tuning**:
  - [PGTune](https://pgtune.leopard.in.ua/) - PostgreSQL configuration wizard
  - [pgtune](https://github.com/le0pard/pgtune) - CLI version
  - [pg_stat_statements](https://www.postgresql.org/docs/current/pgstatstatements.html) - Query statistics

### ArtÃ­culos y Tutoriales

- [PostgreSQL Replication Best Practices](https://www.postgresql.org/docs/current/different-replication-solutions.html)
- [pgpool-II Tutorial](https://www.pgpool.net/docs/latest/en/html/tutorial.html)
- [HAProxy + PostgreSQL Setup Guide](https://www.haproxy.com/blog/the-four-essential-sections-of-an-haproxy-configuration/)
- [Keycloak Clustering with PostgreSQL](https://www.keycloak.org/high-availability/concepts-multi-site)

---

## Licencia

Este proyecto es proporcionado "tal cual" sin garantÃ­as de ningÃºn tipo. Usar bajo su propio riesgo.

---

## Contacto y Soporte

Para preguntas, problemas o contribuciones sobre este proyecto de alta disponibilidad:

- **Issues**: Abrir ticket en el repositorio
- **DocumentaciÃ³n adicional**: Ver carpeta `old/` para configuraciones legacy de Patroni

---

## Historial de Versiones

### v3.0.0 - Febrero 2026 (Actual - Arquitectura 2 Nodos FÃ­sicos) â­ NEW
- âœ… **Arquitectura distribuida en 2 servidores independientes**
  - NODO 1: PostgreSQL PRIMARY + Keycloak-1 (servidor primario)
  - NODO 2: PostgreSQL REPLICA + Keycloak-2 + Proxy (servidor secundario)
- âœ… **pgpool-II configurado por nodo**
  - NODO 1: 1 backend (PRIMARY local) - todas las queries locales
  - NODO 2: 2 backends (PRIMARY remoto + REPLICA local) - routing inteligente
- âœ… **HAProxy configurado por nodo**
  - NODO 1: Solo PRIMARY local
  - NODO 2: Proxy a PRIMARY remoto + REPLICA local
- âœ… **Keycloak Clustering inter-nodos**
  - JGroups TCP con TCPPING discovery entre IPs configurables
  - Active-Active: ambos nodos aceptan trÃ¡fico simultÃ¡neamente
- âœ… **Scripts de despliegue independientes**
  - `deploy-nodo1.sh`: DetecciÃ³n automÃ¡tica de IP
  - `deploy-nodo2.sh`: ConfiguraciÃ³n interactiva con validaciÃ³n de conectividad
- âœ… **Scripts de limpieza por nodo**
  - `cleanup-nodo1.sh` / `cleanup-nodo2.sh`
- âœ… **DocumentaciÃ³n actualizada**
  - GuÃ­as de despliegue separadas por nodo
  - Troubleshooting especÃ­fico para arquitectura distribuida
  - AnÃ¡lisis de performance y latencia por nodo
  - Requisitos de red y firewall

### v2.0.0 - Febrero 2026 (MonolÃ­tico)
- âœ… ImplementaciÃ³n de pgpool-II con query routing automÃ¡tico
- âœ… ConsolidaciÃ³n de tests en script Ãºnico (23 tests)
- âœ… DocumentaciÃ³n completa y profesional
- âœ… Arquitectura optimizada para producciÃ³n (single host)

### v1.0.0 - Inicial
- PostgreSQL Streaming Replication nativa
- HAProxy con routing por puerto
- Keycloak cluster con JGroups
- Scripts de despliegue y testing bÃ¡sicos

---

**Proyecto:** Keycloak High Availability con PostgreSQL Streaming Replication (2 Nodos FÃ­sicos)  
**Arquitectura:** Active-Active Keycloak + PostgreSQL PRIMARY (NODO 1) + REPLICA (NODO 2)  
**Ãšltima actualizaciÃ³n:** Febrero 10, 2026  
**Estado:** âœ… ProducciÃ³n Ready (2-Node Distributed Architecture)
