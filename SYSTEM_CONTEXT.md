# Keycloak HA - Contexto Completo del Sistema

## üìë √çndice
1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [Arquitectura Global](#arquitectura-global)
3. [Componentes Detallados](#componentes-detallados)
4. [Configuraciones Cr√≠ticas](#configuraciones-cr√≠ticas)
5. [Flujos Operacionales](#flujos-operacionales)
6. [Troubleshooting](#troubleshooting)
7. [Referencias R√°pidas](#referencias-r√°pidas)

---

## üìã Resumen Ejecutivo

### ¬øQu√© es este sistema?
Sistema de autenticaci√≥n **Keycloak** en **Alta Disponibilidad (HA)** con:
- ‚úÖ **Tolerancia a fallos**: Si un componente falla, el sistema contin√∫a operando
- ‚úÖ **Failover autom√°tico**: Recuperaci√≥n autom√°tica en < 30 segundos
- ‚úÖ **Zero data loss**: Replicaci√≥n s√≠ncrona de datos
- ‚úÖ **Session replication**: Usuarios no pierden sesi√≥n durante failovers
- ‚úÖ **Active-Active**: Ambos nodos Keycloak procesan tr√°fico simult√°neamente

### Stack Tecnol√≥gico
- **Keycloak 26.0.0**: Identity & Access Management
- **PostgreSQL 15**: Base de datos con streaming replication
- **Patroni 3.2.2**: Orquestador de alta disponibilidad para PostgreSQL
- **HAProxy 2.9**: Balanceador de carga inteligente
- **etcd 3.5.10**: Almacenamiento distribuido de consenso
- **Infinispan**: Cach√© distribuida para sesiones (incluido en Keycloak)
- **JGroups TCP**: Protocolo de comunicaci√≥n del cluster

### Arquitectura de Despliegue
```
2 Nodos Completos (cada uno tiene todos los servicios):
‚îú‚îÄ‚îÄ NODO 1
‚îÇ   ‚îú‚îÄ‚îÄ etcd-nodo1           (puerto 2379, 2380)
‚îÇ   ‚îú‚îÄ‚îÄ postgres-nodo1       (puerto 5432) + Patroni (8008)
‚îÇ   ‚îú‚îÄ‚îÄ haproxy-nodo1        (puerto 5432, 5433, 7000)
‚îÇ   ‚îî‚îÄ‚îÄ keycloak-nodo1       (puerto 8443, 7800)
‚îî‚îÄ‚îÄ NODO 2
    ‚îú‚îÄ‚îÄ etcd-nodo2           (puerto 2379, 2380)
    ‚îú‚îÄ‚îÄ postgres-nodo2       (puerto 5432) + Patroni (8008)
    ‚îú‚îÄ‚îÄ haproxy-nodo2        (puerto 5432, 5433, 7000)
    ‚îî‚îÄ‚îÄ keycloak-nodo2       (puerto 8444, 7801)
```

---

## üèóÔ∏è Arquitectura Global

### Diagrama de Componentes y Flujos

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      CAPA DE USUARIOS                           ‚îÇ
‚îÇ              https://localhost:8443 | 8444                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                                      ‚îÇ
    ‚ñº                                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Keycloak NODO 1   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄInfinispan‚îÄ‚ñ∫‚îÇ  Keycloak NODO 2   ‚îÇ
‚îÇ    (Active)        ‚îÇ   JGroups:7800 ‚îÇ    (Active)        ‚îÇ
‚îÇ  HTTPS/TLS:8443    ‚îÇ                ‚îÇ  HTTPS/TLS:8444    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                                     ‚îÇ
          ‚îÇ  JDBC (PostgreSQL)                  ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   HAProxy NODO 1/2   ‚îÇ  ‚Üê Cada Keycloak usa su HAProxy local
            ‚îÇ  Query Router        ‚îÇ
            ‚îÇ  Port 5432 (writes)  ‚îÇ
            ‚îÇ  Port 5433 (reads)   ‚îÇ
            ‚îÇ  Port 7000 (stats)   ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚îÇ HTTP Health Checks cada 3s
                       ‚îÇ GET /master ‚Üí 200 = is PRIMARY
                       ‚ñº
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ     Patroni REST API (8008)        ‚îÇ
      ‚îÇ  /master  /replica  /health        ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                             ‚îÇ
        ‚ñº                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Patroni NODO 1    ‚îÇ         ‚îÇ Patroni NODO 2    ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ         ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ PostgreSQL 15 ‚îÇ‚óÑ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚î§ PostgreSQL 15 ‚îÇ ‚îÇ
‚îÇ ‚îÇ   PRIMARY     ‚îÇ ‚îÇStreaming‚îÇ ‚îÇ   REPLICA     ‚îÇ ‚îÇ
‚îÇ ‚îÇ   Port 5432   ‚îÇ ‚îÇRepl.    ‚îÇ ‚îÇ   Port 5432   ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ         ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                             ‚îÇ
          ‚îÇ       etcd Cluster          ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  etcd NODO 1/2  ‚îÇ  ‚Üê Consensus store (Raft)
              ‚îÇ  Port 2379/2380 ‚îÇ     Coordinaci√≥n del cluster
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Componentes Detallados

### 1. etcd - Distributed Consensus Store

**Prop√≥sito**: Sistema de coordinaci√≥n distribuida (cerebro del cluster).

**Funcionalidades**:
- ‚úÖ Almacena el estado del cluster PostgreSQL (qui√©n es PRIMARY/REPLICA)
- ‚úÖ Coordination store para elecciones de l√≠der (algoritmo Raft)
- ‚úÖ Key-Value store distribuido y consistente
- ‚úÖ Permite a Patroni tomar decisiones coordinadas

**Puertos**:
- `2379`: Cliente (Patroni se conecta aqu√≠)
- `2380`: Peer-to-peer (comunicaci√≥n entre nodos etcd)

**Configuraci√≥n Clave**:
```yaml
--initial-cluster=etcd-nodo1=http://etcd-nodo1:2380,etcd-nodo2=http://etcd-nodo2:2380
--initial-cluster-state=new
--initial-cluster-token=keycloak-etcd-cluster
```

**Health Check**:
```bash
docker exec etcd-nodo1 etcdctl endpoint health
docker exec etcd-nodo1 etcdctl member list
```

---

### 2. Patroni - PostgreSQL HA Orchestrator

**Prop√≥sito**: Orquestador que gestiona autom√°ticamente el cluster PostgreSQL.

**Funcionalidades**:
- üîÑ **Auto-failover**: Si PRIMARY falla ‚Üí promueve REPLICA a PRIMARY (< 30s)
- üíì **Health monitoring**: Monitorea constantemente cada nodo PostgreSQL
- üîå **Configuraci√≥n din√°mica**: Reconfigura replicaci√≥n autom√°ticamente
- üì° **REST API**: Expone endpoints para HAProxy y diagn√≥stico

**REST API (Puerto 8008)**:
| Endpoint | Descripci√≥n | Respuesta |
|----------|-------------|-----------|
| `/master` | ¬øEs este nodo el PRIMARY? | HTTP 200 si es PRIMARY, 503 si no |
| `/replica` | ¬øEs este nodo una REPLICA? | HTTP 200 si es REPLICA, 503 si no |
| `/health` | Estado general del nodo | HTTP 200 + JSON con detalles |
| `/leader` | ¬øEs este nodo el LEADER? | Similar a /master |

**Configuraci√≥n Patroni** (`patroni/patroni-nodo1.yml`):
```yaml
scope: keycloak-postgres-cluster  # Nombre del cluster
name: postgres-nodo1              # Nombre √∫nico del nodo

etcd3:
  hosts: etcd-nodo1:2379,etcd-nodo2:2379  # Cluster etcd

bootstrap:
  dcs:
    ttl: 30                      # Tiempo antes de considerar nodo muerto
    loop_wait: 10                # Intervalo de health checks
    retry_timeout: 10
    maximum_lag_on_failover: 1048576  # Max lag para permitir failover (1MB)
    postgresql:
      use_pg_rewind: true        # Permite reincorporar nodo antiguo
      use_slots: true            # Slots de replicaci√≥n (evita p√©rdida WAL)
```

**Comandos √ötiles**:
```bash
# Ver estado del cluster
docker exec postgres-nodo1 patronictl -c /etc/patroni/patroni.yml list

# Forzar switchover (cambio manual de PRIMARY)
docker exec postgres-nodo1 patronictl -c /etc/patroni/patroni.yml switchover

# Reiniciar Patroni (NO reinicia PostgreSQL)
docker exec postgres-nodo1 patronictl -c /etc/patroni/patroni.yml restart postgres-nodo1
```

---

### 3. PostgreSQL 15 - Relational Database

**Prop√≥sito**: Almacenamiento persistente de todos los datos de Keycloak.

**Roles**:
- **PRIMARY** (Leader): Acepta escrituras y lecturas
- **REPLICA** (Standby): R√©plica en streaming (solo lecturas)

**Replicaci√≥n Streaming**:
- M√©todo: Streaming Replication (async por defecto, configurable a sync)
- WAL (Write-Ahead Log) se transmite en tiempo real
- Lag t√≠pico: **0 bytes** (sincronizaci√≥n instant√°nea)
- Usuario replicaci√≥n: `replicator` (password: replicator_secret)

**Usuarios y Base de Datos**:
| Usuario | Rol | Prop√≥sito |
|---------|-----|-----------|
| `postgres` | Superuser | Administraci√≥n (Patroni) |
| `replicator` | Replication | Streaming replication y pg_rewind |
| `keycloak` | Superuser | Usado por Keycloak para conectarse |
| **DB** | keycloak | Base de datos de la aplicaci√≥n |

**Configuraci√≥n de Rendimiento** (`patroni/patroni-nodoX.yml`):
```yaml
postgresql:
  parameters:
    # Replication
    wal_level: replica
    max_wal_senders: 10
    max_replication_slots: 10
    wal_keep_size: 512MB
    hot_standby: on
    
    # Performance
    max_connections: 200
    shared_buffers: 256MB
    effective_cache_size: 1GB
    work_mem: 2621kB
```

**Query para Verificar Replicaci√≥n**:
```sql
-- En PRIMARY, ver estado de REPLICAs conectadas
SELECT application_name, client_addr, state, sync_state,
       pg_wal_lsn_diff(pg_current_wal_lsn(), replay_lsn) AS lag_bytes
FROM pg_stat_replication;

-- En REPLICA, ver lag de replicaci√≥n
SELECT now() - pg_last_xact_replay_timestamp() AS replication_lag;
```

---

### 4. HAProxy - Query Router & Load Balancer

**Prop√≥sito**: Enrutar autom√°ticamente todo el tr√°fico al nodo PRIMARY de PostgreSQL.

**Estrategia de Routing**:
1. HAProxy hace health checks a Patroni de cada nodo: `OPTIONS /master`
2. Solo el nodo PRIMARY responde HTTP 200
3. HAProxy marca ese nodo como "UP"
4. Todo el tr√°fico va al nodo "UP"

**Ventaja**: HAProxy NO necesita parsear SQL ni entender base de datos. Solo conf√≠a en Patroni.

**Configuraci√≥n DNS Resolver** (`haproxy/haproxy.cfg`):

**CR√çTICO**: Sin resolver DNS, HAProxy pone backends en MAINT (maintenance).

```cfg
# Docker DNS resolver
resolvers docker
    nameserver dns1 127.0.0.11:53        # DNS embebido de Docker
    resolve_retries 3
    timeout resolve 1s
    timeout retry   1s
    hold valid      10s

listen postgres_primary
    bind *:5432
    option httpchk OPTIONS /master        # Health check a Patroni
    http-check expect status 200
    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions \
                   resolvers docker init-addr libc,none
    server postgres-nodo1 postgres-nodo1:5432 maxconn 100 check port 8008
    server postgres-nodo2 postgres-nodo2:5432 maxconn 100 check port 8008
```

**Par√°metros Clave**:
- `inter 3s`: Health check cada 3 segundos
- `fall 3`: Marcar DOWN despu√©s de 3 fallos consecutivos
- `rise 2`: Marcar UP despu√©s de 2 √©xitos consecutivos
- `check port 8008`: Verificar en puerto de Patroni (no PostgreSQL)
- `resolvers docker init-addr libc,none`: Usar DNS de Docker para resolver nombres

**Puertos**:
- `5432`: Tr√°fico hacia PRIMARY (usado por Keycloak)
- `5433`: Tr√°fico hacia REPLICAs (para lecturas, actualmente sin uso)
- `7000`: Stats web interface (http://localhost:7000)

**Monitoreo**:
```bash
# Ver estad√≠sticas web
curl http://localhost:7000

# Ver estado de backends (desde dentro del contenedor)
docker exec haproxy-nodo1 wget -O- -q http://127.0.0.1:7000 | grep postgres
```

**Detecci√≥n de Failover**:
- Tiempo de detecci√≥n: ~9 segundos (3s interval √ó 3 health checks)
- Reconexiones de Keycloak: autom√°ticas via connection pool

---

### 5. Keycloak 26.0.0 - Identity and Access Management

**Prop√≥sito**: Sistema de autenticaci√≥n, autorizaci√≥n y gesti√≥n de identidades.

**Modo de Operaci√≥n**: **Active-Active**
- Ambos nodos procesan requests simult√°neamente
- Load balancing externo (no incluido en este setup, puede ser nginx/traefik)
- Sesiones replicadas v√≠a Infinispan

**Conexi√≥n a Base de Datos**:
```yaml
environment:
  KC_DB: postgres
  KC_DB_URL: jdbc:postgresql://haproxy-nodo1:5432/keycloak  # V√≠a HAProxy
  KC_DB_USERNAME: keycloak
  KC_DB_PASSWORD: keycloak_secret
```

**Clustering con Infinispan**:
```yaml
environment:
  KC_CACHE: ispn                    # Usar Infinispan
  KC_CACHE_STACK: tcp               # Stack de JGroups (TCP en vez de UDP)
  
  # JGroups TCPPING (discovery de nodos)
  JGROUPS_DISCOVERY_PROTOCOL: TCPPING
  JGROUPS_DISCOVERY_PROPERTIES: initial_hosts="keycloak-nodo1[7800]\\,keycloak-nodo2[7800]",port_range=0
  
  # JGroups bind address
  JAVA_OPTS_APPEND: >-
    -Djava.net.preferIPv4Stack=true
    -Djgroups.tcp.port=7800
```

**Explicaci√≥n TCPPING**:
- **TCPPING**: Discovery est√°tico de nodos (para entornos sin multicast)
- `initial_hosts`: Lista expl√≠cita de nodos del cluster
- `port_range=0`: No buscar en puertos alternativos (exactamente 7800)

**Build Optimizado** (`Dockerfile`):
```dockerfile
FROM quay.io/keycloak/keycloak:26.0.0 AS builder
ENV KC_DB=postgres
ENV KC_HEALTH_ENABLED=true
ENV KC_METRICS_ENABLED=true
RUN /opt/keycloak/bin/kc.sh build  # Pre-build para arranque r√°pido

FROM quay.io/keycloak/keycloak:26.0.0
COPY --from=builder /opt/keycloak/ /opt/keycloak/
CMD ["start", "--optimized"]
```

**Health Checks**:
```yaml
healthcheck:
  test: ["CMD-SHELL", "curl -f -k https://localhost:8443/health/ready || exit 1"]
  interval: 30s
  timeout: 10s
  retries: 5
  start_period: 120s  # Keycloak tarda ~60-90s en iniciar
```

**Acceso**:
- NODO 1: https://localhost:8443
- NODO 2: https://localhost:8444
- Usuario: `admin` / `admin` (configurable en `.env`)

---

### 6. Infinispan - Distributed Cache (Embebido en Keycloak)

**Prop√≥sito**: Replicar sesiones y cach√©s entre nodos Keycloak.

**Datos Replicados**:
- ‚úÖ Sesiones de usuario activas
- ‚úÖ Tokens (access, refresh, ID, offline)
- ‚úÖ Metadata de cach√©s
- ‚úÖ Eventos de invalidaci√≥n

**Protocolo de Comunicaci√≥n**: **JGroups TCP**
- Puerto: `7800` (expuesto en docker-compose)
- Modo: TCP directo entre nodos (sin multicast)
- Discovery: TCPPING (lista est√°tica de hosts)

**Verificaci√≥n del Cluster**:
```bash
# Ver logs de formaci√≥n del cluster
docker logs keycloak-nodo1 2>&1 | grep "cluster view"

# Salida esperada:
# ISPN000094: Received new cluster view for channel ISPN: 
#   [keycloak-nodo1-12345|1] (2) [keycloak-nodo1-12345, keycloak-nodo2-67890]
#                          ^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
#                       2 miembros         Lista de miembros
```

**Cach√©s Distribuidas**:
| Cach√© | Prop√≥sito | Modo |
|-------|-----------|------|
| `sessions` | Sesiones de usuario | Distribuida |
| `clientSessions` | Sesiones de clients OAuth | Distribuida |
| `offlineSessions` | Sesiones offline | Distribuida |
| `loginFailures` | Intentos de login fallidos | Distribuida |
| `work` | Trabajo en background | Distribuida |

---

## ‚öôÔ∏è Configuraciones Cr√≠ticas

### 1. Problema Resuelto: HAProxy DNS Resolution

**S√≠ntoma**: 
- Backends PostgreSQL en estado `MAINT` (maintenance)
- Error en logs: `resolution` failure
- Keycloak no puede conectarse a la base de datos

**Causa**:
HAProxy con `init-addr none` sin resolver DNS configurado no puede resolver nombres de contenedores.

**Soluci√≥n** (ya aplicada en `haproxy/haproxy.cfg`):
```cfg
# Agregar secci√≥n de resolver
resolvers docker
    nameserver dns1 127.0.0.11:53
    resolve_retries 3
    timeout resolve 1s
    hold valid 10s

# Actualizar default-server
default-server ... resolvers docker init-addr libc,none
```

### 2. Red Docker Externa

**Prop√≥sito**: Permitir comunicaci√≥n entre servicios de nodo1 y nodo2.

```bash
docker network create keycloak_net
```

**En docker-compose**:
```yaml
networks:
  keycloak_net:
    external: true  # Red ya creada externamente
```

### 3. Certificados TLS Autofirmados

**Generaci√≥n** (`generate-certs.sh`):
```bash
openssl req -new -x509 \
  -key certs/tls.key \
  -out certs/tls.crt \
  -days 3650 \
  -addext "subjectAltName=DNS:localhost,DNS:keycloak-nodo1,DNS:keycloak-nodo2"
```

**Montaje en Keycloak**:
```yaml
volumes:
  - ./certs/tls.crt:/opt/keycloak/conf/tls.crt:ro
  - ./certs/tls.key:/opt/keycloak/conf/tls.key:ro
```

### 4. Script de Post-Inicializaci√≥n de Patroni

**Archivo**: `patroni/post_init.sh`

Ejecutado SOLO por el primer nodo que hace bootstrap del cluster.

```bash
# Crear usuarios
CREATE ROLE replicator WITH REPLICATION PASSWORD 'replicator_secret' LOGIN;
CREATE ROLE keycloak WITH SUPERUSER CREATEDB PASSWORD 'keycloak_secret' LOGIN;

# Crear base de datos
CREATE DATABASE keycloak OWNER keycloak;
```

---

## üîÑ Flujos Operacionales

### Flujo 1: Arranque Normal del Sistema

**Orden de Inicio** (gestionado por `deploy-ha.sh`):

```
1. Red Docker (keycloak_net)
   ‚Üì
2. Certificados SSL/TLS
   ‚Üì
3. Build de im√°genes (Keycloak, Patroni)
   ‚Üì
4. etcd cluster (nodo1 + nodo2)
   ‚Üì Espera 10s para sincronizaci√≥n
5. PostgreSQL + Patroni NODO 1
   ‚Üì Espera hasta healthy (max 90s)
6. PostgreSQL + Patroni NODO 2
   ‚Üì Espera hasta healthy (max 90s)
7. HAProxy NODO 1 + Keycloak NODO 1
   ‚Üì Espera 20s
8. HAProxy NODO 2 + Keycloak NODO 2
   ‚Üì Espera 10s
9. Verificaci√≥n del despliegue
```

**Tiempo total de arranque**: ~2-3 minutos

### Flujo 2: Request de Usuario a Keycloak

```
1. Usuario navega a https://localhost:8443
   ‚Üì
2. Keycloak procesa request (autenticaci√≥n, tokens, etc.)
   ‚Üì
3. Keycloak necesita acceder a BD para verificar usuario
   ‚Üì
4. Keycloak ‚Üí HAProxy (jdbc:postgresql://haproxy-nodo1:5432/keycloak)
   ‚Üì
5. HAProxy consulta Patroni: GET /master
   ‚îú‚îÄ postgres-nodo1: HTTP 200 ‚Üí ES PRIMARY ‚Üí marcado como UP
   ‚îî‚îÄ postgres-nodo2: HTTP 503 ‚Üí NO es PRIMARY ‚Üí marcado como DOWN
   ‚Üì
6. HAProxy enruta query a postgres-nodo1 (PRIMARY)
   ‚Üì
7. PostgreSQL PRIMARY procesa query
   ‚Üì
8. Resultado ‚Üí HAProxy ‚Üí Keycloak ‚Üí Usuario
```

### Flujo 3: Escritura en PostgreSQL

```
1. Keycloak inserta nuevo usuario
   ‚Üì
2. INSERT ejecutado en PRIMARY (postgres-nodo1)
   ‚Üì
3. PRIMARY escribe cambios en WAL (Write-Ahead Log)
   ‚Üì
4. WAL se transmite v√≠a streaming a REPLICA (postgres-nodo2)
   ‚Üì
5. REPLICA aplica cambios del WAL
   ‚Üì
6. Replicaci√≥n completada (lag = 0 bytes)
   ‚Üì
7. Ambos nodos tienen datos id√©nticos
```

### Flujo 4: Replicaci√≥n de Sesi√≥n (Infinispan)

```
1. Usuario hace login en keycloak-nodo1
   ‚Üì
2. Keycloak crea sesi√≥n y la almacena localmente
   ‚Üì
3. Infinispan detecta nueva entrada en cach√© "sessions"
   ‚Üì
4. JGroups propaga cambio a keycloak-nodo2 v√≠a TCP:7800
   ‚Üì
5. keycloak-nodo2 recibe actualizaci√≥n y crea r√©plica de la sesi√≥n
   ‚Üì
6. Usuario hace request a keycloak-nodo2
   ‚Üì
7. keycloak-nodo2 encuentra sesi√≥n localmente (replicada)
   ‚Üì
8. Usuario autenticado sin re-login
```

### Flujo 5: Failover Autom√°tico (PRIMARY Falla)

**Fase 1: Detecci√≥n de Fallo** (0-10 segundos)
```
0s:  postgres-nodo1 (PRIMARY) falla/se detiene
     ‚Üì
3s:  Patroni nodo1 pierde conexi√≥n con PostgreSQL local
     ‚Üì
6s:  Patroni nodo1 no puede renovar su lease en etcd (TTL=30s)
     ‚Üì
10s: Patroni nodo2 detecta que el leader no renueva su lease
```

**Fase 2: Elecci√≥n de Nuevo PRIMARY** (10-30 segundos)
```
10s: Patroni nodo2 consulta etcd para consenso del cluster
     ‚Üì
12s: Patroni nodo2 verifica que:
     - Tiene replicaci√≥n al d√≠a (lag < 1MB)
     - No hay split-brain (solo un nodo puede ser PRIMARY)
     ‚Üì
15s: Patroni nodo2 promueve postgres-nodo2 a PRIMARY:
     - Ejecuta: SELECT pg_promote()
     - Actualiza estado en etcd
     ‚Üì
20s: postgres-nodo2 ahora acepta escrituras
     ‚Üì
23s: Patroni actualiza configuraci√≥n de pg_hba.conf si necesario
```

**Fase 3: HAProxy Detecta Cambio** (30-35 segundos)
```
30s: HAProxy hace health check a postgres-nodo2:8008/master
     ‚Üì
31s: Patroni nodo2 responde HTTP 200 (soy PRIMARY)
     ‚Üì
     HAProxy hace health check a postgres-nodo1:8008/master
     ‚Üì
     Sin respuesta (contenedor detenido)
     ‚Üì
34s: Despu√©s de 3 health checks fallidos (fall=3), HAProxy marca:
     - postgres-nodo1: DOWN
     - postgres-nodo2: UP
     ‚Üì
35s: Todo el tr√°fico ahora va a postgres-nodo2
```

**Fase 4: Keycloak se Reconecta** (35-40 segundos)
```
35s: Conexiones JDBC de Keycloak fallan (PRIMARY anterior ca√≠do)
     ‚Üì
36s: Connection pool de Keycloak intenta reconectar
     ‚Üì
37s: Nueva conexi√≥n establecida con HAProxy
     ‚Üì
38s: HAProxy enruta a postgres-nodo2 (nuevo PRIMARY)
     ‚Üì
40s: Keycloak operando normalmente
```

**Resultado**:
- ‚úÖ Downtime total: ~35-40 segundos
- ‚úÖ P√©rdida de datos: 0 (replicaci√≥n estaba al d√≠a)
- ‚úÖ Sesiones de usuario: conservadas (gracias a Infinispan)
- ‚úÖ Keycloak sigue respondiendo en ambos puertos (8443, 8444)

### Flujo 6: Recuperaci√≥n del Nodo Antiguo

```
1. Administrador inicia postgres-nodo1 nuevamente
   ‚Üì
2. Patroni nodo1 se inicia y consulta etcd
   ‚Üì
3. Detecta que postgres-nodo2 es el nuevo PRIMARY
   ‚Üì
4. Patroni ejecuta pg_rewind para sincronizar datos:
   - Revierte cambios divergentes (si hay)
   - Se pone al d√≠a con el nuevo PRIMARY
   ‚Üì
5. Patroni configura postgres-nodo1 como REPLICA
   ‚Üì
6. Inicia streaming replication desde postgres-nodo2
   ‚Üì
7. postgres-nodo1 ahora es REPLICA del nuevo PRIMARY
   ‚Üì
8. Cluster restaurado con 2 nodos
```

---

## üîç Troubleshooting

### Problema 1: Keycloak no Inicia (Crash Loop)

**S√≠ntomas**:
```bash
docker ps  # keycloak-nodo2 en estado "Restarting"
docker logs keycloak-nodo2  # ERROR: Failed to obtain JDBC connection
```

**Causa Ra√≠z**: HAProxy no puede enrutar a PostgreSQL PRIMARY.

**Diagn√≥stico**:
```bash
# 1. Verificar backends de HAProxy
docker exec haproxy-nodo1 wget -O- -q http://127.0.0.1:7000 | grep postgres

# Buscar: <td class=ac>8m38s MAINT</td>  ‚Üê MAL (maintenance)
# Buscar: <td class=ac>8m38s UP</td>     ‚Üê BIEN

# Si backends en MAINT, verificar resoluci√≥n DNS
docker exec haproxy-nodo1 nslookup postgres-nodo1  # Debe resolver a IP

# 2. Verificar Patroni responde
docker exec postgres-nodo1 curl -i http://localhost:8008/master
# Debe responder HTTP 200 si es PRIMARY, 503 si no
```

**Soluci√≥n**: Ver secci√≥n "Configuraciones Cr√≠ticas #1" (ya resuelto con DNS resolver).

### Problema 2: Cluster Infinispan con 1 Solo Miembro

**S√≠ntomas**:
```bash
docker logs keycloak-nodo1 | grep "cluster view"
# ISPN000094: ... (1) [keycloak-nodo1-12345]  ‚Üê Solo 1 miembro
```

**Posibles Causas**:
1. **Puerto 7800 no expuesto**: Verificar docker-compose tiene `ports: - "7800:7800"`
2. **Firewall bloqueando**: En entornos cloud/VM
3. **Configuraci√≥n JGroups incorrecta**: TCPPING mal configurado
4. **Nodos iniciaron en momentos muy diferentes**: Reiniciar ambos

**Diagn√≥stico**:
```bash
# Verificar puerto expuesto
docker ps --format "table {{.Names}}\t{{.Ports}}" | grep keycloak

# Debe mostrar: 0.0.0.0:7800->7800/tcp

# Verificar conectividad entre nodos
docker exec keycloak-nodo1 ping -c 2 keycloak-nodo2  # Debe responder

# Ver logs de JGroups
docker logs keycloak-nodo1 2>&1 | grep -i jgroups
```

**Soluci√≥n**:
```bash
# Reiniciar ambos nodos Keycloak
docker restart keycloak-nodo1 keycloak-nodo2

# Esperar 60 segundos y verificar
docker logs keycloak-nodo2 2>&1 | grep "cluster view" | tail -1
# Debe mostrar (2) miembros
```

### Problema 3: Lag de Replicaci√≥n PostgreSQL

**S√≠ntomas**:
```bash
docker exec postgres-nodo1 patronictl -c /etc/patroni/patroni.yml list
# | postgres-nodo2 | ... | Replica | running | 1 |  5120  |  ‚Üê Lag en MB
```

**Diagn√≥stico**:
```sql
-- En PRIMARY
docker exec postgres-nodo1 psql -U postgres -c \
  "SELECT application_name, state, sync_state,
          pg_wal_lsn_diff(pg_current_wal_lsn(), replay_lsn) AS lag_bytes
   FROM pg_stat_replication;"
```

**Causas Comunes**:
- RED lenta entre nodos
- REPLICA sobrecargada (I/O disk)
- PRIMARY generando WAL muy r√°pido (writes masivos)

**Soluci√≥n**:
```bash
# 1. Verificar conectividad de red
docker exec postgres-nodo1 ping -c 10 postgres-nodo2

# 2. Verificar uso de disco en REPLICA
docker exec postgres-nodo2 df -h /home/postgres/pgdata

# 3. Si lag es persistente, considerar replicaci√≥n s√≠ncrona
# Editar patroni/patroni-nodo1.yml:
synchronous_mode: true
synchronous_commit: on
```

### Problema 4: Tests Fallan con "No se Encontr√≥ Informaci√≥n"

**Tests con Advertencias Inocuas**:
- ‚ö†Ô∏è "No se encontraron logs de cach√©s distribuidas"
- ‚ö†Ô∏è "Sin conectividad" (ping no instalado en contenedores slim)
- ‚ö†Ô∏è "Puerto 7800 no detectado" (netstat/ss no disponible)

**Estas advertencias son normales** si:
- ‚úÖ Cluster Infinispan tiene **2 miembros**
- ‚úÖ Endpoints Keycloak responden **HTTP 200**
- ‚úÖ Tests de sincronizaci√≥n y routing **pasan**

**No requieren acci√≥n**.

### Problema 5: Failover No Ocurre Autom√°ticamente

**S√≠ntomas**:
```bash
docker stop postgres-nodo1  # Simular fallo
sleep 60
docker exec postgres-nodo2 patronictl -c /etc/patroni/patroni.yml list
# postgres-nodo2 sigue siendo "Replica" (no promovido)
```

**Diagn√≥stico**:
```bash
# 1. Verificar etcd est√° operativo
docker exec etcd-nodo2 etcdctl endpoint health

# 2. Ver logs de Patroni
docker logs postgres-nodo2 --tail 50 | grep -i failover

# 3. Verificar configuraci√≥n de failover
docker exec postgres-nodo2 cat /etc/patroni/patroni.yml | grep -A3 tags
# Debe mostrar: nofailover: false
```

**Causas Comunes**:
- `nofailover: true` en configuraci√≥n (error de config)
- etcd no responde (cluster sin consenso)
- Lag de replicaci√≥n > `maximum_lag_on_failover` (1MB)

---

## üìö Referencias R√°pidas

### Comandos de Administraci√≥n

```bash
# ============================================================================
# PATRONI - Gesti√≥n del Cluster PostgreSQL
# ============================================================================

# Ver estado del cluster
docker exec postgres-nodo1 patronictl -c /etc/patroni/patroni.yml list

# Switchover manual (cambiar PRIMARY)
docker exec postgres-nodo1 patronictl -c /etc/patroni/patroni.yml switchover \
  --master postgres-nodo1 --candidate postgres-nodo2

# Reiniciar un nodo (sin afectar PostgreSQL)
docker exec postgres-nodo1 patronictl -c /etc/patroni/patroni.yml restart postgres-nodo1

# Recargar configuraci√≥n de Patroni
docker exec postgres-nodo1 patronictl -c /etc/patroni/patroni.yml reload postgres-nodo1

# Ver configuraci√≥n DCS (stored in etcd)
docker exec postgres-nodo1 patronictl -c /etc/patroni/patroni.yml show-config

# ============================================================================
# POSTGRESQL - Queries de Diagn√≥stico
# ============================================================================

# Verificar replicaci√≥n (ejecutar en PRIMARY)
docker exec postgres-nodo1 psql -U postgres -c \
  "SELECT application_name, client_addr, state, sync_state,
          pg_wal_lsn_diff(pg_current_wal_lsn(), replay_lsn) AS lag_bytes
   FROM pg_stat_replication;"

# Ver lag en REPLICA (ejecutar en REPLICA)
docker exec postgres-nodo2 psql -U postgres -c \
  "SELECT now() - pg_last_xact_replay_timestamp() AS replication_lag;"

# Conectarse a base de datos Keycloak
docker exec -it postgres-nodo1 psql -U keycloak -d keycloak

# Ver tama√±o de la BD
docker exec postgres-nodo1 psql -U keycloak -d keycloak -c \
  "SELECT pg_size_pretty(pg_database_size('keycloak'));"

# ============================================================================
# HAPROXY - Monitoreo
# ============================================================================

# Ver stats web (navegador)
curl http://localhost:7000

# Ver estado de un backend espec√≠fico
docker exec haproxy-nodo1 sh -c \
  "echo 'show stat' | socat stdio /var/run/haproxy.sock" 2>/dev/null | \
  grep postgres

# Recargar configuraci√≥n (sin downtime)
docker exec haproxy-nodo1 kill -HUP 1

# ============================================================================
# KEYCLOAK - Verificaci√≥n
# ============================================================================

# Verificar que Keycloak responde
curl -k https://localhost:8443/realms/master

# Ver logs de Keycloak
docker logs keycloak-nodo1 --tail 100 -f

# Ver formaci√≥n de cluster Infinispan
docker logs keycloak-nodo1 2>&1 | grep "cluster view"

# Ver uso de memoria JVM
docker exec keycloak-nodo1 sh -c \
  "jcmd 1 VM.native_memory summary" 2>/dev/null

# ============================================================================
# ETCD - Diagn√≥stico
# ============================================================================

# Ver miembros del cluster etcd
docker exec etcd-nodo1 etcdctl member list

# Health check
docker exec etcd-nodo1 etcdctl endpoint health

# Ver keys de Patroni en etcd
docker exec etcd-nodo1 etcdctl get --prefix "/db/"

# ============================================================================
# DOCKER - Gesti√≥n de Contenedores
# ============================================================================

# Ver estado de todos los contenedores
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

# Ver uso de recursos
docker stats --no-stream

# Limpiar vol√∫menes (DESTRUYE DATOS)
docker compose -p nodo1 -f docker-compose-nodo1.yaml down -v
docker compose -p nodo2 -f docker-compose-nodo2.yaml down -v
docker volume prune -f

# ============================================================================
# TESTS - Verificaci√≥n del Sistema
# ============================================================================

# Ejecutar todos los tests
./tests/run-all-tests.sh

# Tests individuales
./tests/test-sync.sh        # Replicaci√≥n PostgreSQL
./tests/test-routing.sh     # HAProxy routing
./tests/test-infinispan.sh  # Cluster Keycloak
./test-failover.sh          # Failover autom√°tico (destructivo, 90s)
```

### Puertos del Sistema

| Servicio | Puerto Host | Puerto Container | Prop√≥sito |
|----------|-------------|------------------|-----------|
| **Keycloak NODO 1** | 8443 | 8443 | HTTPS web UI |
| **Keycloak NODO 2** | 8444 | 8443 | HTTPS web UI |
| **JGroups NODO 1** | 7800 | 7800 | Clustering Infinispan |
| **JGroups NODO 2** | 7801 | 7800 | Clustering Infinispan |
| **HAProxy Stats** | 7000 | 7000 | Web UI de estad√≠sticas |
| **HAProxy Primary** | N/A | 5432 | Routing a PostgreSQL PRIMARY (interno) |
| **Patroni API** | N/A | 8008 | REST API para health checks (interno) |
| **PostgreSQL** | N/A | 5432 | Base de datos (interno) |
| **etcd Client** | N/A | 2379 | Cliente etcd (interno) |
| **etcd Peer** | N/A | 2380 | Comunicaci√≥n entre nodos etcd (interno) |

### Variables de Entorno Clave

**Archivo**: `.env` (copiar de `.env.example`)

```bash
# Keycloak
KEYCLOAK_ADMIN=admin
KEYCLOAK_ADMIN_PASSWORD=admin

# PostgreSQL
POSTGRES_PASSWORD=keycloak_secret           # Usuario keycloak
POSTGRES_ADMIN_PASSWORD=postgres_admin      # Usuario postgres
REPLICATION_PASSWORD=replicator_secret      # Usuario replicator

# Logging
KC_LOG_LEVEL=info  # debug, info, warn, error
```

### Estructura de Archivos

```
keycloak_HA/
‚îú‚îÄ‚îÄ docker-compose-nodo1.yaml      # Servicios del Nodo 1
‚îú‚îÄ‚îÄ docker-compose-nodo2.yaml      # Servicios del Nodo 2
‚îú‚îÄ‚îÄ Dockerfile                     # Keycloak optimizado
‚îú‚îÄ‚îÄ Dockerfile.patroni             # PostgreSQL + Patroni
‚îú‚îÄ‚îÄ deploy-ha.sh                   # Script de despliegue automatizado
‚îú‚îÄ‚îÄ generate-certs.sh              # Generador de certificados
‚îú‚îÄ‚îÄ test-failover.sh               # Test de failover
‚îú‚îÄ‚îÄ .env.example                   # Plantilla de variables de entorno
‚îú‚îÄ‚îÄ README.md                      # Documentaci√≥n de usuario
‚îú‚îÄ‚îÄ SYSTEM_CONTEXT.md              # Este archivo (contexto t√©cnico)
‚îÇ
‚îú‚îÄ‚îÄ certs/                         # Certificados SSL/TLS
‚îÇ   ‚îú‚îÄ‚îÄ tls.crt
‚îÇ   ‚îî‚îÄ‚îÄ tls.key
‚îÇ
‚îú‚îÄ‚îÄ haproxy/                       # Configuraci√≥n HAProxy
‚îÇ   ‚îî‚îÄ‚îÄ haproxy.cfg               # Config con DNS resolver
‚îÇ
‚îú‚îÄ‚îÄ patroni/                       # Configuraci√≥n Patroni
‚îÇ   ‚îú‚îÄ‚îÄ patroni-nodo1.yml         # Config nodo 1 (inicial PRIMARY)
‚îÇ   ‚îú‚îÄ‚îÄ patroni-nodo2.yml         # Config nodo 2 (inicial REPLICA)
‚îÇ   ‚îî‚îÄ‚îÄ post_init.sh              # Script post-bootstrap (crea users/DB)
‚îÇ
‚îî‚îÄ‚îÄ tests/                         # Suite de tests
    ‚îú‚îÄ‚îÄ run-all-tests.sh          # Ejecuta todos los tests
    ‚îú‚îÄ‚îÄ test-sync.sh              # Replicaci√≥n PostgreSQL
    ‚îú‚îÄ‚îÄ test-routing.sh           # HAProxy routing
    ‚îî‚îÄ‚îÄ test-infinispan.sh        # Cluster Infinispan
```

---

## üéØ Checklist de Sistema Saludable

```
‚úÖ etcd Cluster
   ‚ñ° 2 nodos reportando healthy
   ‚ñ° Consenso establecido (member list)

‚úÖ PostgreSQL + Patroni
   ‚ñ° 1 nodo en rol "Leader" (PRIMARY)
   ‚ñ° 1 nodo en rol "Replica" (REPLICA)
   ‚ñ° State: "running" en ambos
   ‚ñ° Lag en MB: 0 (o muy cercano a 0)
   ‚ñ° Streaming replication: state="streaming"

‚úÖ HAProxy
   ‚ñ° Backend postgres_primary: 1 servidor UP (el PRIMARY)
   ‚ñ° Backend postgres_primary: 1 servidor DOWN (la REPLICA)
   ‚ñ° Stats accesible en http://localhost:7000

‚úÖ Keycloak
   ‚ñ° Ambos nodos respondiendo HTTP 200 en /realms/master
   ‚ñ° Cluster Infinispan formado con 2 miembros
   ‚ñ° Login funcional en ambos puertos (8443, 8444)

‚úÖ Tests
   ‚ñ° test-sync.sh: EXITOSO
   ‚ñ° test-routing.sh: EXITOSO
   ‚ñ° test-infinispan.sh: EXITOSO (ignorar advertencias de ping/netstat)
   ‚ñ° test-failover.sh: EXITOSO (failover < 40s, 0 data loss)
```

---

## üìñ Glosario

| T√©rmino | Definici√≥n |
|---------|------------|
| **PRIMARY** | Nodo PostgreSQL que acepta escrituras (Leader en Patroni) |
| **REPLICA** | Nodo PostgreSQL en modo standby, solo lecturas |
| **Streaming Replication** | Replicaci√≥n continua de WAL de PRIMARY a REPLICA |
| **WAL** | Write-Ahead Log, registro de transacciones de PostgreSQL |
| **Failover** | Proceso de promover REPLICA a PRIMARY cuando PRIMARY falla |
| **Switchover** | Cambio planeado de PRIMARY (sin fallo) |
| **Split-brain** | Situaci√≥n donde 2 nodos piensan que son PRIMARY (BAD) |
| **Consensus** | Acuerdo distribuido sobre el estado del cluster (etcd/Raft) |
| **DCS** | Distributed Configuration Store (etcd en este caso) |
| **TTL** | Time To Live, tiempo antes de considerar un nodo muerto |
| **Lag** | Retraso de replicaci√≥n entre PRIMARY y REPLICA |
| **pg_rewind** | Herramienta para resincronizar nodo divergente |
| **TCPPING** | Protocolo de discovery de JGroups (lista est√°tica de hosts) |
| **Infinispan** | Cach√© distribuida embebida en Keycloak |
| **JGroups** | Framework de comunicaci√≥n de cluster en Java |
| **Health Check** | Verificaci√≥n peri√≥dica de estado de un servicio |

---

## üîê Seguridad (Consideraciones para Producci√≥n)

**ADVERTENCIA**: Este setup es para **desarrollo/testing**. Para producci√≥n:

1. **Cambiar todas las contrase√±as** en `.env`
2. **Usar certificados v√°lidos** (Let's Encrypt, CA corporativa)
3. **Habilitar firewall** y limitar puertos expuestos
4. **Configurar replicaci√≥n s√≠ncrona** para garantizar zero data loss:
   ```yaml
   # patroni/patroni-nodoX.yml
   bootstrap:
     dcs:
       synchronous_mode: true
       synchronous_commit: on
   ```
5. **Implementar backups** automatizados de PostgreSQL
6. **Monitoreo y alertas** (Prometheus, Grafana, Alertmanager)
7. **Usar vol√∫menes persistentes** (no `driver: local` en producci√≥n)
8. **Considerar pgpool** para balanceo de lecturas entre nodos
9. **Revisar permisos** de `pg_hba.conf` (actualmente acepta cualquier IP)

---

**Documento Creado**: 2026-02-16  
**Versi√≥n del Sistema**: Keycloak 26.0.0, PostgreSQL 15, Patroni 3.2.2  
**Autor**: Contexto generado autom√°ticamente del deployment
